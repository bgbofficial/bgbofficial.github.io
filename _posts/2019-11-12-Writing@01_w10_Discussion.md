---
layout: post
title: Writing@01_w10_Discussion
date: 2019-11-12
tag: Writing
mathjax: true
---
# Discussion 

## 2. Reviewing in class

### How should we structure the Discussion?

The Discussion should answer the following questions, and possibly in the following order. You can thus use the answers to structure your Discussion. This gives you a relatively easy template to follow.

1. What are my most important findings?

2. Do these findings support what I set out to demonstrate at the beginning of the paper?

3. How do my findings compare with that others have found? How consistent are they?

4. What is my personal interpretation of my findings?

5. What other possible interpretations are there?

6. What are the limitations of my study? What other factors could have influenced my findings? Have I reported everything that could make my findings invalid?

7. Do any of the interpretations reveal a possible flaw (i.e. defect, error) in my experiment?

8. Do my interpretations contribute some new understanding of the problem that I have investigated? In which case do they suggest a shortcoming in, or an advance on, the work of others?

9. What external validity do my findings have? How could my findings be generalized to other areas?

10. What possible implications or applications do my findings have? What support can I give for such implications?

11. What further research would be needed to explain the issues raised by my findings? Will I do this research myself or do I want to throw it open to the community?

    

## 7. Good examples

### 7.1 (4)Short discussion

 We have delineated the spatiotemporal dynamics, genomic landscape and functional consequences of naive CD8$^+$ T cells undergoing intrahepatic priming (Extended Data Fig. [10](https://www.nature.com/articles/s41586-019-1620-6#Fig14)). We showed that hepatocellular presentation leads to a CD8$^+$ T cell dysfunction that is distinct from T cell alterations reported in other viral infections and cancer and, as such, is not readily responsive to anti-PD-L1 treatment. As immune checkpoint inhibitors are beginning to be tested in patients persistently infected with HBV, the results reported here should help to interpret the outcome of those studies and eventually inform the design of modified trials in selected cohorts of patients. Our data identify IL-2 as a potent immunotherapeutic that can rescue CD8$^+$ T cells rendered dysfunctional by hepatocellular priming. Thus, IL-2-based strategies should be considered for the treatment of chronic HBV infection. （第一句点题。第二句给出结果。）

\- "Dynamics and genomic landscape of CD8$^+$​ T cells undergoing hepatic priming", *Nature*. 2019-10-08.

短讨论比较注重突出结果，总共有137个单词。

### 7.2 (5)Long discussion

`One striking aspect of our atlas is that`$^{[1][2]}$ the distribution of semantically selective areas is relatively symmetrical across the two cerebral hemispheres. `This finding is inconsistent with`$^{[3]}$ human lesion studies that support the idea that semantic representation is lateralized to the left hemisphere[13](https://www.nature.com/articles/nature17637#ref13). `However`, many fMRI studies of semantic representation find only modest lateralization[1](https://www.nature.com/articles/nature17637#ref1) and one study that used narrative stories found highly bilateral results similar to ours[2](https://www.nature.com/articles/nature17637#ref2). (前面这句话举例出了和自己实验相同和不同的例子)`This suggests that` right hemisphere areas may respond more strongly to narrative stimuli than to the words and short phrases used in most studies. `Still`\*, `more research will be needed to determine` what roles these left- and right-hemisphere semantic areas have in language comprehension.（这句话十分断然，肯定。这是对自己结果的讨论。其中，still这个词语用的很地道和精髓。整个结构是层次递进的：先给出主要发现的结果；然后从人们认为语言的左脑单边侧化--有研究认为适度侧化--有研究认为与他们相似的高度双边侧化；最后给出讨论，再用Still给出进一步的东西。这一段是主要研究结果的那方面）

`Another interesting aspect of these results is that` the organization of semantically selective brain areas seems to be highly consistent across individuals. `This might suggest` that innate anatomical connectivity or cortical cytoarchitecture constrains the organization of high-level semantic representations[28](https://www.nature.com/articles/nature17637#ref28),[29](https://www.nature.com/articles/nature17637#ref29). `It is also possible that` this is owing to common life experiences of the subjects, all of whom were raised and educated in Western industrial societies. `Future studies that include subjects from more diverse backgrounds will be needed to determine` how much of this organizational consistency reflects innate brain structure versus experience.（might、possible这些词汇的运用，显出这个段落十分缓和，由于没有大规模的调查。这一段是带有猜测的结果的那方面）

`One` `limitation`\*（限制性词语） `of PrAGMATiC as used here is that` each area is assumed to be functionally homogeneous. `This is a common assumption` in the design and analysis of many neuroimaging studies[30](https://www.nature.com/articles/nature17637#ref30). `However`, many cortical maps, including semantic maps in visual cortex[14](https://www.nature.com/articles/nature17637#ref14), `seem to contain` smoothly changing gradients of representation. `It should be possible to modify` the PrAGMATiC algorithm to model functional gradients explicitly. `This will provide an objective tool for determining` whether the semantic maps found here are best described as homogeneous areas or as gradients.（这一段讲局限性。并且说明了原因和可改进方法。注意插入句。从同质性假设谈论到似乎有梯度的不同。提出了修改模型，最后给出试验，做出试验能判断同质模型还是渐变模型好。）

`Data-driven approaches are commonplace in studies of` human neuroanatomy[31](https://www.nature.com/articles/nature17637#ref31) and resting state networks[26](https://www.nature.com/articles/nature17637#ref26),[32](https://www.nature.com/articles/nature17637#ref32), `but`\* `are only beginning to be used`\* in functional imaging[14](https://www.nature.com/articles/nature17637#ref14),[15](https://www.nature.com/articles/nature17637#ref15).` Our study demonstrates` the power and efficiency of data-driven approaches for functional mapping of the human brain. `Although` our experiment used a simple design in which subjects only listened to stories, the data were rich enough to produce a comprehensive atlas of semantically selective areas. `Furthermore`, `our data-driven framework is quite general`\*. Other properties of language can be mapped (even in this same data set) by using feature spaces that reflect phonemes, syntax and so on. Complex semantic models that incorporate information beyond word co-occurrence can be tested and compared quantitatively. `The generalizability of these models can also be tested by` using stimuli beyond autobiographical stories. `It is sometimes difficult to synthesize the results of` data-driven experiments with those from hypothesis-driven experiments, `but future methodological and theoretical developments should help to bridge this divide`\*. `We expect` that the semantic atlas presented here will be useful for many researchers investigating the neurobiological basis of language. We `also` expect that this atlas can be refined and expanded by incorporating results from future studies. `To facilitate this`, we have creatsed a detailed interactive version of the semantic atlas that can be explored online at http://gallantlab.org/huth2016.（结尾段落。第一句总结使用的数据驱动方法在成熟领域和刚发展的领域。but are用的很精髓。紧接着说明了本文的数据驱动方法在这个领域十分好。Although又紧急转折说明了本方法是比较简单的，但很有用。Futhermore，强调了通用性，解释并且举例。此外提出一些该理论是可补充得，并且在将来可以发展：bridge this divide。提出了一些基于此更远研究的希望：We expect，and also expect。区别两者expect的不同。最后给出资源与数据。）

\-  “Natural speech reveals the semantic maps that tile human cerebral cortex,” *Nature*, 2016-04-28.

这篇文章的讨论部分，有三个阅读的好处，总共558个单词。（1）突出了本文第2部分的每个点；（2）跨学科；（3）长讨论。用的好的短语这样标注：`One striking aspect of our atlas is that`$^{[1][2]}$ ，其中[1] [2]指的是在第二节Reviewing in class中对应的讨论方法。用的极好的连词或短语用 \* 星号进行标注：`Still`\*。这些词语与短语都必须进入个人的学术英语写作语料库（因为实在太好用了）。并且在第一段的故事情节是，（1）他们的研究方向；（2）怎么确定这个研究方向的。

## 9. After Class: Tasks

1. Writing Journal. 阅读选定文章的Discussion并记录收获和体会，下次上课带上。（注：可参考课程资料"Week 10 Discussion - 9.Tasks "中的条目来记录，也可自行安排。）

2. 主题阅读：Titile, Abstract, Conclusion。参考书目如下：

   - （1）Chapter 12, 13, 19 (Adrian Wallwork. English for Writing Research Paper (2nd Edition), Springer. 2016
   - （2）Chapter 10, 11 (Margaret Cargill & O'Connor Patrick. Writing Scientific Research Articles: Strategy and Steps. 2nd Edition. Wiley-Blackwell. 2013.)
   - （3）Unit 5: Writing summaries (Swales J., Feak C. Academic Writing for Graduate Students: Essential Tasks and Skills. Michigan, ELT. 2012)  

3. 期末安排
   - week15：提交Final exam
   - week16-17：One On One
   - week18-19：考试，开卷

## 10. Homeworks

### 10.1 Notices that I must do in reading the discussion of a paper

1. Read your selected articles and examine the following questions. What moves can you identify in thr Discussion section? For example:

   - Move1-Backgroud information (research purposes, theory, methodology, optinal);

   - Move2-Summarizing and reporting key results (obligatory);

   - Move3-Commenting on the key results (making claims, explaining the results, comparing the new work with the previous studies, offering alternative explanations);

   - Move4-Stating the limitations of the study (optional, but probable in some fields);

   - Move5-Making recommendations for future implementation and/or for future research (optional);
   
2. Note the words or phrases of generality. In the Discussion section, a common device is to use one of the following "phrases of generality". For example:

   Overall / In general / On the whole / In the main / With ... exception(s);

   The overall results indicate..., / The results indicate, overall, that..., / With one exception, the experimental samples resisted...

3. Limitations in Discussion. Here are some typical formulations for stating limitations in one's research scope. For example: It should be noted that this study has been primarily concerned with ..., / This analysis has concentrated on ..., / The findings of this study are restricted to ..., /This study has addressed only the question of ...,/ We would like to point out that we have not ...

   Here are some typical openings for statements that firmly state that certain conclusions should not be drawn. For example: However, the fingdings do not simply...,/ The results of this study cannot be taken as evidence for ...,/ Unfortunately, we are unabel to detemine from this data ...,/ The lack of ... means that we cannot be certain ...,/ Notwithstanding its limitations, this study does suggest ...,/ Despite its preliminary character, the research reported here would seem to indicate ...,/ However exploratory, this study may offer some insight into ...,/

4. What about the length of sentences in Discussion. Long or short? How many words in long sentences?

### 10.2 The discussion of 1st paper (Nat Mach Intell, Jun. 2019)

The proposed MAP-NN, enhanced by the radiologist in the loop, performs favourably or comparably relative to the clinically used iterative reconstruction methods implemented by the three leading CT vendors. Once the MAP-NN is trained, the DL-based denoising process is highly efficient (about 100 slices per second per mapping depth) and easy to use in clinical practice, while iterative reconstruction techniques are time-consuming and subject to significant artefacts.

Compared to previously published DL-based denoising networks[14](https://www.nature.com/articles/s42256-019-0057-9#ref-CR14),[15](https://www.nature.com/articles/s42256-019-0057-9#ref-CR15),[16](https://www.nature.com/articles/s42256-019-0057-9#ref-CR16),[17](https://www.nature.com/articles/s42256-019-0057-9#ref-CR17),[19](https://www.nature.com/articles/s42256-019-0057-9#ref-CR19),[20](https://www.nature.com/articles/s42256-019-0057-9#ref-CR20),[21](https://www.nature.com/articles/s42256-019-0057-9#ref-CR21),[22](https://www.nature.com/articles/s42256-019-0057-9#ref-CR22),[23](https://www.nature.com/articles/s42256-019-0057-9#ref-CR23), which learn the denoising mapping from images collected at a specific low-dose setting to their NDCT counterparts, our MAP-NN can be viewed as a significant refinement and a major extension that learns not only intermediate denoised images through multiple CLONE stages but also the associated noise reduction direction. The number of CLONE modules, also known as the mapping depth, is a key parameter, and the radiologists have the best judgement regarding the selection of an optimal mapping depth in a task-specific fashion. MAP-NN with CLONEs provides a cost-effective and user-friendly interface between DL and radiologists, enabling mixed/augmented intelligence beyond what standalone DL could achieve. We provide more details about the differences between the conventional denoising model and the proposed progressive denoising model in Supplementary Notes [1](https://www.nature.com/articles/s42256-019-0057-9#MOESM1) and [2](https://www.nature.com/articles/s42256-019-0057-9#MOESM1).

Our MAP-NN systematically demonstrates that the DL approach can provide a similar or better image quality in terms of structural fidelity and noise suppression as commercial IR methods performing image reconstruction directly from raw data. Most importantly for clinical use, the DL approach is computationally much more efficient than IR. The DL approach can thus already effectively compete with IR solutions, and potentially replace the IR approach. Furthermore, because DL methods can be vendor agnostic, institutions that have CT scanners of various brands and from different vendors can utilize the MAP-NN model to produce similar image appearances, which is not possible with commercial IR techniques. Even though all reconstruction and processing algorithms are commercial products, our post-processing algorithm can be embedded within image viewer software, which is independent of any vendor. Currently, unique changes in image appearance are associated with vendor-specific reconstruction programs. This is an obstacle for large-scale radiomics studies, and could be streamlined using DL techniques in the future.

However, there are some limitations of this study. First, as an overall comparative study, the MAP-NN has not been optimized to either a specific vendor or a particular body region. The collection of more data will help improve the denoising performance and enhance the statistical significance of the denoising gains over the IR results. Second, LDCT and NDCT slices in a testing set may not be in perfect registration, which can affect the evaluation scores to some degree. Finally, our DL method was selected to be applicable to CT scans from all three vendors, from which we cannot have access to raw data. More powerful DL methods cannot be implemented without the data format. Despite these limitations, our overall conclusion has been encouraging that DL is either better than or comparable to IR. In collaboration with a vendor, our algorithm could be specifically trained with their data and achieve an even better performance than what we have described here using our agnostic algorithm. With the availability of raw data, CT denoising can be performed from the sinogram domain to the image space, utilizing all the information for the best denoising results. Clearly, it is now time for CT vendors to open their data format, perform machine learning and develop the next generation of CT image reconstruction algorithms in the DL framework.

In conclusion, our DL method provides better or similar image quality compared to commercial IR techniques from three CT vendors, and there is great potential for optimizing DL-based CT reconstruction methods that handle sinogram data directly.

\-  “Competitive performance of a modularized deep neural network compared to commercial algorithms for low-dose CT image reconstruction,” *Nat Mach Intell*, vol. 1, no. 6, pp. 269–276, Jun. 2019.

### 10.3 The discussion of 2nd paper (Nat Biomed Eng, Nov. 2019)

To better understand the deep-learning model, we analyse the semantic representations learned from the model. Generally speaking, successful generation of volumetric images is possible only if the model is able to learn the semantic representation of the 3D structure from the input projections. Thus, for the same volume, the representations obtained via learning from different angular projections should be similar, since they describe the same underlying 3D scene. In Fig. [6a](https://www.nature.com/articles/s41551-019-0466-4#Fig6), we visualize the feature maps extracted from the transformation module for two testing samples. For visualization purposes, only 5 randomly chosen channels among the 4,096 feature maps are shown, each with a size of 4 × 4 pixels. The feature maps learned from different numbers of 2D projections are displayed separately in different columns. The results show that, when different 2D views are given, the model extracts similar semantic representations of the underlying 3D scene. Furthermore, Fig. [6b](https://www.nature.com/articles/s41551-019-0466-4#Fig6) shows the visualization of *t*-distributed stochastic neighbour embedding (*t*-SNE) for the feature maps of 15 testing samples. The *t*-SNE technique is commonly used to visualize high-dimensional data by embedding each sample as a point in a 2D space[38](https://www.nature.com/articles/s41551-019-0466-4#ref-CR38). The four points in a cluster of the same colour represent the learned features from one-, two-, five- and ten-view reconstructions. The figure shows clustering behaviour for feature maps from the same sample, indicating that the model learns a similar representation from different 2D projections.

We also measure the similarity of the embedding representations by calculating the Euclidean distance between two feature maps. In this way, we compute a similarity score, ranging from 0 to 1, where high similarity (a score approaching 1) indicates that the distance between two feature maps is close to zero. We plot a correlation matrix (Fig. [6c](https://www.nature.com/articles/s41551-019-0466-4#Fig6)) among 50 randomly selected testing samples, with their feature representations extracted from one-view and two-view reconstruction models. The highest values stand out in the diagonal of the correlation matrix whereas other off-diagonal values remain relatively low. This illustrates that the two sets of feature representations learned from one-view and two-view projections for the same 3D scene are more similar or closer in Euclidean distance space compared with the feature representations learned from other different 3D scenes. This provides additional evidence supporting the capability of the model to learn a semantic representation of the 3D scene with a single projection.

Robustness against possible irregular breathing patterns is important for future clinical implementation of the approach. The robustness of deep networks against various perturbations is an intense area of research in artificial intelligence[39](https://www.nature.com/articles/s41551-019-0466-4#ref-CR39),[40](https://www.nature.com/articles/s41551-019-0466-4#ref-CR40),[41](https://www.nature.com/articles/s41551-019-0466-4#ref-CR41),[42](https://www.nature.com/articles/s41551-019-0466-4#ref-CR42),[43](https://www.nature.com/articles/s41551-019-0466-4#ref-CR43),[44](https://www.nature.com/articles/s41551-019-0466-4#ref-CR44),[45](https://www.nature.com/articles/s41551-019-0466-4#ref-CR45),[46](https://www.nature.com/articles/s41551-019-0466-4#ref-CR46). As summarized in ref. [43](https://www.nature.com/articles/s41551-019-0466-4#ref-CR43), possible solutions come in three categories: (1) the modification of network architectures (for example, adding more layers, changing the loss function and modifying the activation functions); (2) the use of external models as a network add-on to detect out-of-distribution data (for example, using an external detector to rectify the irregular data); and (3) the modification of the training-data distribution or the training strategy (for example, adding regularization, data augmentation or leveraging adversarial training). In (1), the efforts are focused on refining the learning models. In (2), irregular motions might be regarded as out-of-distribution data, where some potential techniques, such as a detector subnetwork[41](https://www.nature.com/articles/s41551-019-0466-4#ref-CR41) or the confidence-based method[42](https://www.nature.com/articles/s41551-019-0466-4#ref-CR42),[44](https://www.nature.com/articles/s41551-019-0466-4#ref-CR44), might be useful for detecting irregular input. Among the various methods, the modification of the training-data distribution is arguably the most straightforward way to proceed. The rationale is that if the irregularities can be incorporated effectively into the training dataset and the training strategy can be adjusted accordingly, the robustness of the trained model would be enhanced. To a certain extent, this has been elaborated in the example in Supplementary Fig. [7](https://www.nature.com/articles/s41551-019-0466-4#MOESM1), where it is demonstrated that, because of the inclusion of augmented training datasets with rotational transformations, the deep-learning approach is much more robust against a small rotation of the imaging subject than a conventional principal component analysis (PCA)-based method. Quantitative results of the study for the testing sample presented in Supplementary Fig. [7](https://www.nature.com/articles/s41551-019-0466-4#MOESM1) are shown in Supplementary Table [1](https://www.nature.com/articles/s41551-019-0466-4#MOESM1).

#### Outlook

We have described a deep-learning approach for volumetric imaging with ultra-sparse data sampling and a patient-specific prior. The data-driven strategy is capable of holistically extracting the feature characteristics embedded in a single projection or in a few 2D projections, and of transforming them into the corresponding 3D image through model learning. The image-feature space transformation plays an essential role in the ultra-sparse image reconstruction. At the training stage, the method incorporates diverse forms of a priori knowledge into the reconstruction. The manifold-mapping function is learned from the training datasets, rather than relying on any ad hoc form of motion trajectory. Although we have used X-ray imaging and patient-specific data, the concept and implementation of the approach could be extended to other imaging modalities or to other data domains with ultra-sparse sampling. Practically, single-view imaging represents a potential solution for many image-guided interventional procedures and may help to simplify the hardware of tomographic imaging systems.

\-  “Patient-specific reconstruction of volumetric computed tomography images from a single projection view via deep learning,” *Nat Biomed Eng*, vol. 3, no. 11, pp. 880–888, Nov. 2019.

### 10.4 The discussion of 3rd paper (MAI)

Discussions and conclusions

In this paper, we propose a novel method based on the Wasserstein generative adversarial network to remove the Rician noise in MR images while effectively preserving the structural details. This network aims to process 3D volume data using a 3D convolutional neural network. In addition to the introduction of the WGAN framework, there are two more advantages to our method: the innovative generator structure and mixed weighted loss function. The generator is constructed with an autoencoder structure, which symmetrically contains convolutional and deconvolutional layers, aided by a residual structure. Another improvement of our method is the adaptation of the mixed loss function, which combines the MSE and perceptual losses with a weighted form.

The experimental results demonstrate that with the help of WGAN and perceptual loss, the CNN-based method is significantly improved in both qualitative and quantitative aspects. Compared to several state-of-the-art methods, including BM3D, PRI-NLM3D and CNN3D, our proposed RED-WGAN effectively avoids oversmoothing effects while preserving more details. Furthermore, to validate the robustness and generalization of our model, we trained our model with several specific noise levels and tested it on various noise levels. Meanwhile, real noisy clinical data were involved. In both cases, the proposed RED-WGAN model achieved a performance better than the traditional methods in both visual effects and quantitative results.

The computational cost of the deep learning-based method is worth mentioning. The training stage is the costliest step. Although the training procedure is usually performed on the GPU, it is still time-consuming. For our training set, when we alternatingly train the generator and discriminator networks, each epoch takes approximately 40 min. Although other methods, such as BM4D and PRI-NLM3D, do not need to train, their running times are much longer than the DL-based methods. In this paper, the average execution times for the clinical dataset for BM4D, PRI-NLM3D, CNN3D and RED-WGAN were 5.73, 4.16, 0.17 and 0.16 s, respectively. In practice, the running time for DL-based methods can be further reduced by using GPU for testing.

In conclusion, the results obtained in the paper are encouraging and efficiently demonstrate the potential of deep learning-based methods for MRI denoising. In the future, instead of training on a specific noise level, we will try to extend our method to a more general form for different noise levels. Furthermore, incorporating the image reconstruction method may be interesting.

\- “Denoising of 3D magnetic resonance images using a residual encoder–decoder Wasserstein generative adversarial network,” *Medical Image Analysis*, vol. 55, pp. 165–180, Jul. 2019.

### 10.5  The discussion of 4th paper (TMI)

With the development of CSC in recent years, CSC has been proven useful in many imaging problems, including super-resolution, image fusion, image decomposition and so on. Instead of dividing an image into overlapped patches, CSC directly works on the whole image, which maintains more details and avoids artifacts caused by patch aggregation. In this paper, we propose two methods based on CSC. The basic version introduces CSC into the PWLS reconstruction framework. To further improve the performance and preserve more structural information, gradient regularization on feature maps is imposed into the basic version. Qualitative and quantitative results demonstrate the merits of our methods.

In the experiments of Section IV-A and IV-B, the filters and parameters were the same, showing the generalization of the proposed methods and that there is no need to adjust the filters or the parameters patient by patient. We also examined the impacts of filters on our method. The experimental results show that PWLS-CSCGR can work well even with only four filters. PWLS-CSCGR is also robust to the training set or even without the training set and can be treated as an unsupervised learning method.

Importantly, another issue is the computational time. The main cost of our methods depends on two parts: training the filters and the reconstruction. Training 32 filters with 10 images costs 85 s of GPU. Because this operation is offline and there is no need for a large training set, this part will not be the main problem. On the other hand, the reconstruction is time-consuming. Although our methods have a similar heavy computational burden to PWLS-DL, several techniques, including parallel computing and advanced optimization methods, can be applied for acceleration.

One of the most important deep learning models is CNN, which is also based on the convolution operator. For CSC, a signal can be represented by a summation of convolutions between a set of filters and the corresponding feature maps, and the key point is to calculate the feature maps with certain (predetermined or adaptive) filters. CNN trains the cascaded filters to convolve with the inputs. Furthermore, current CNN-based methods still lack theoretical proof. Most deep learning methods are data-driven, and the results cannot be guaranteed without sufficient training data. However, CSC, as an unsupervised learning method, has a strict mathematical proof. This method is robust to the number of training samples (as shown in Sec. IV-C.3 and IV-C.4) and even without training data. On the other hand, the same groups analyzed the relationship between the CSC and CNN methods in [59], [60] and found that assuming that our signals originate from the multi-layer CSC model, the layered-thresholding pursuit algorithm for decomposing a given measurement vector $Y$ completely equals the forward propagation in CNNs. This interesting finding provides a new way to explore the interpretability of deep learning.

In conclusion, inspired by successful applications of CSC in the field of signal processing, we explored the potential of this method incorporating a PWLS image reconstruction framework, resulting in two novel algorithms referred to as PWLS-CSC and PWLS-CSCGR. We evaluated the proposed algorithms with simulated and real data. In the experimental results, our methods have been shown to be competitive with several state-of-art methods. The robustness of our methods was also investigated by extensive analysis with experimental configurations. In our future work, we will extend our methods to other CT imaging topics, such as metal artifact reduction and LDCT. Furthermore, the combination with deep learning-based methods is also an interesting direction.

\- “Convolutional Sparse Coding for Compressed Sensing CT Reconstruction,” *IEEE Transactions on Medical Imaging*, pp. 1–1, 2019.