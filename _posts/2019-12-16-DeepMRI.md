# 0. Overview

- image-domain learning, *e.g.*, [Exploiting DCNN, 2016](http://dev.ismrm.org//2016/1778.html)    [Deep artifact learning for CS, 2017](http://arxiv.org/abs/1703.01120 )

- data-domain or k-space learning

  *e.g*., [RAKI, 2019](https://doi.org/10.1002/mrm.27420)    [K-space deep learning, 2018](https://arxiv.org/abs/1805.03779)

- transform learning (direct from k-space to image)

  *e.g*., [AUTOMAP, 2018](https://doi.org/10.1038/nature25988)

- hybrid-domain learning (unrolled loop, e.g., variational network)  

  alternate between denoising/dealiasing and reconstruction from k-space
  *e.g*., [Deep ADMM-net, 2016](https://papers.nips.cc/paper/6406-deep-admm-net-for-compressive-sensing-mri)    [variational network, 2018](https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.26977)    [DC-CNN DMRI, 2017](https://doi.org/10.1109/tmi.2017.2760978)    [cycleGAN, 2018](https://doi.org/10.1109/TMI.2018.2820120)    [mag and phase networks, 2018](https://doi.org/10.1109/TBME.2018.2821699)    [ME-CNN, 2019](https://link.springer.com/content/pdf/10.1007%2F978-3-030-32251-9_77.pdf)

# *1. Image-domain learning

![1](https://wzwimg-1300620626.cos.ap-chengdu.myqcloud.com/githubimg/clipboard_20191216043852.png)

👍🏽: 简单、快

👎🏽: 空域很多欠采样噪声

# 2. Data-domain or k-space learning (RAKI)

![2](https://wzwimg-1300620626.cos.ap-chengdu.myqcloud.com/githubimg/clipboard_20191216044220.png)

👍🏽: 简单、快 (“还有非线性的 GRAPPA”)  

👍🏽: 更少的数据：从自动校正的数据中学习

👎🏽: 更难以表示局部图像特征

## 2.1 RAKI 框架和Loss

RAKI (robust artificial‐neural‐networks for k‐space interpolation)

![2](https://onlinelibrary.wiley.com/cms/attachment/bd02b40d-0cd3-41d7-9517-608d2023500b/mrm27420-fig-0001-m.jpg)

![1](https://onlinelibrary.wiley.com/cms/attachment/aeca94af-a0e4-44a4-b357-ca00ece5166e/mrm27420-math-0025.png)

## 2.2 RAKI 公式



## 2.3 RAKI 结果

该重建方案使用了一种特定于扫描的深度学习方法，使用针对有限ACS数据训练的卷积神经网络来改进基于线性k空间插值的方法的重建质量。

**TODO**：复现RAKI的最新2019版。

# 3. Transform learning (AUTOMAP)

![3](https://wzwimg-1300620626.cos.ap-chengdu.myqcloud.com/githubimg/clipboard_20191216044252.png)

👍🏽: 真正意义上的数据驱动；潜在地避免了模型的非适配

👎🏽: 需要更大的内存需求

## 3.1 AUTOMAP 框架和Loss

automated transform by manifold approximation

![1](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnature25988/MediaObjects/41586_2018_Article_BFnature25988_Fig1_HTML.jpg)





## 3.2 AUTOMAP 公式





## 3.3 AUTOMAP 结果

Source code is available from the corresponding author upon reasonable request.

**TODO**：复现AUTOMAP

# 4. Hybrid-domain learning (DC-CNN)

![4](https://wzwimg-1300620626.cos.ap-chengdu.myqcloud.com/githubimg/clipboard_20191216044318.png)

👍🏽: 基于模型驱动：对k空间数据和空域先验数据使用模型

👍🏽: 优化策略上更加具有可解释性

👎🏽: 重复迭代和反复的 FFT/iFFT ，因此有更多的计算量

## 4.1 DC-CNN 公式

根据字典学习磁共振重建，学到的知识存在字典 $\mathbf{D}$ 里，并给出约束，可以得到（1）式：

$$
\begin{aligned} \begin{aligned}&\underset{\mathbf {x}, \mathbf {D}, \{\boldsymbol{\gamma }_i\} }{\text {min.}}&\sum _i \left( \Vert \mathbf {R}_i\mathbf {x} - \mathbf {D} \boldsymbol{\gamma }_i \Vert _2^2 + \nu \Vert \boldsymbol{\gamma }_i \Vert _0 \right) + \lambda \Vert \mathbf {y}- \mathbf {F}_u \mathbf {x}\Vert ^2_2 \end{aligned} \end{aligned}
$$

（1）式这里，可以将字典 $\mathbf{D}$ 的学习过程用cnn参数更新过程来替换，得到（2）式：

$$
\begin{aligned} \begin{aligned}&\underset{\mathbf {x}, \boldsymbol{\theta }}{\text {min.}}&\Vert \mathbf {x}- f_{\text {cnn}}(\mathbf {x}_u | \boldsymbol{\theta }) \Vert ^2_2 + \lambda \Vert \mathbf {F}_u \mathbf {x}- \mathbf {y}\Vert _2^2 \\ 
\end{aligned} \end{aligned} \tag{2}
$$

根据 [DL-MRI, 2011](https://doi.org/10.1109/TMI.2010.2090538) ，可以得到（2）式的在k空间的解析解：

$$
\begin{aligned}\hat{\mathbf {x}}_{\text {rec}}(k) = {\left\{ \begin{array}{ll} \hat{\mathbf {x}}_{\text {cnn}}(k) &{} \text {if } k \not \in \varOmega \\ \frac{\hat{\mathbf {x}}_{\text {cnn}}(k) + \lambda \hat{\mathbf {x}}_u(k)}{1+\lambda } &{} \text {if } k \in \varOmega \end{array}\right. } \end{aligned} \tag{3}
$$

其中，$\hat{\mathbf {x}}_{\text {cnn}} = \mathbf {F} f_{\text {cnn}}(\mathbf {x}_u | \boldsymbol {\theta })$ , $\hat{\mathbf {x}}_u = \mathbf {F}\mathbf {x}_u$ ，这里的 $\mathbf {F}$ 是傅里叶编码矩阵。

把（3）式子用python代码写下来：

```python
# noisy case
out = (x_cnn + lambda * kspace_samples) / (1 + lambda)
# noiseless case
out = (1 - mask) * x + kspace_samples
```

## 4.2 DC-CNN 

Input: 欠采样的复数空域 $\mathbf{x}_u$；(训练还使用了  欠采样的k空间数据 $\mathbf{k}_u$，mask，全采样的复数空域 $\mathbf{x}$** )

**output: 复数空域**；

整个网络是叠加的：

![1](https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-59050-9_51/MediaObjects/450577_1_En_51_Fig1_HTML.gif)

一个组件包含了（Input → CNN1 → DC → Output），其正向训练的网络结构是：

**CNN层**：

$\mathbf{x}_u$输入：（空域欠采样数据、空域全采样数据、k空间欠采样数据、欠采样mask），在这之前，要把一个复数空域矩阵被分成两个实数矩阵。假设一共有256张空域复数图，每张图分辨率是 `(128, 128)`，每个点都输复数， 则该矩阵可以表示为 `(256, 128, 128)`。通过分成两个实数矩阵，则该数据多了一个维度`(256, 128, 128, 2)`；

$C_1$：第一层卷积层；

$C_2$~$C_{d-1}$：第二层卷积层~第d-1层卷积层；

$C_{rec}$：汇聚重建层，此层的输出特征图shape与输入层数据的shape一致；

$\mathbf{x}_{cnn}$ ：CNN输出层，此层是一个残差网络， $\mathbf{x}_{cnn}=\mathbf{x}_u + C_{rec}$，这里的 + 是做按元素相加，非串联，其输出shape与输入层shape一致。

**DC层**：

其伪代码可以表示为：

```python
# data consistency layer
dft2 = FFT2DLayer(x_cnn)
dc = DataConsistencyWithMaskLayer(dft2, mask, kspace_samples)
idft2 = FFT2DLayer(dc, inv=True)
x_rec = idft2
```

其中，`DataConsistencyWithMaskLayer` 里主要是用到了（3）式 这样的操作

```python
# noisy case
dc = (dft2 + lambda * kspace_samples) / (1 + lambda)
# noiseless case
dc = (1 - mask) * dft2 + kspace_samples
```

## 4.3 DC-CNN 结果

![1](https://wzwimg-1300620626.cos.ap-chengdu.myqcloud.com/githubimg/myplot.png)

Figure 1: a, b, c

使用DC-CNN的预测函数进行，随意找一个mri图像，采样率是 25%。

输入一张空域复数（取绝对值后，如图1中的b。）；将b图中的复数空域25%采样，则通过一次正向运算，得到图1中的c；将b图总的复数空域25%采样，直接FFT后得到a图。

**数据**：这里使用了256张膝盖附近连续切片(128, 128)的x方向进行训练；连续切片的256张y方向作为验证集；切片的z方向作为测试集；

**深度学习框架**：用的远古框架 `Theano`，目前已停止开发和维护。

**TODO**：用Pytorch 重写 DC-CNN 的最新版。

**Cardiac Motion**：

<video src="https://wzwimg-1300620626.cos.ap-chengdu.myqcloud.com/githubimg/cardiac_motion.mp4" controls="controls" width='30%' height='30%' style="max-width: 100%; display: block; margin-left: auto; margin-right: auto;">
your browser does not support the video tag
</video>