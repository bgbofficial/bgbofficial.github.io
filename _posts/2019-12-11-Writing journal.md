---
layout: post
title: Writing@01_w10_Discussion
date: 2019-11-12
tag: Writing
mathjax: true

---

# Writing Journal

Zhiwen Wang, 2019323040005, College of Computer Science, Sichuan University

# Week 5 Target journal

## 1. Task

ç›®æ ‡æœŸåˆŠçš„é€‰æ‹©ï¼ˆè¡¨æ ¼ï¼‰

<font size=2>Table 1. Rating preferred journals in terms of key criteria for maximizing your publication success.</font>

| Journal name                                              | Recent publication of similar work and novelty               | Match of scope and recent content to your work | Page charges or Open Access costs                            | Time to publication             | impact         |
| --------------------------------------------------------- | ------------------------------------------------------------ | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------------- | -------------- |
| 1. IEEE TRANSACTIONS ON MEDICAL IMAGING (IEEE TMI)        | ENGINEERING, BIOMEDICAL;<br/><br/>ENGINEERING, ELECTRICAL & ELECTRONIC;<br/><br/>RADIOLOGY, NUCLEAR MEDICINE & MEDICAL IMAGING;<br/><br/>COMPUTER SCIENCE, INTERDISCIPLINARY APPLICATIONS;<br/><br/>IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY; | MEDICAL IMAGING                                | Free(Page charge $250 for overlength<br/>manuscripts or color figures)<br/>Above 10 pages | Average 5.4months<br/>(Monthly) | 7.816          |
| 2. IEEE TRANSACTIONS ON IMAGE PROCESSING (IEEE TIP)       | COMPUTER SCIENCE, SOFTWARE, GRAPHICS, PROGRAMMING;<br/><br/>COMPUTER SCIENCE, THEORY & METHODS;<br/><br/>ENGINEERING, ELECTRICAL & ELECTRONIC;<br/><br/>COMPUTER SCIENCE, SOFTWARE ENGINEERING;<br/><br/>COMPUTER SCIENCE, ARTIFICIAL INTELLIGENCE; | COMPUTER SCIENCE, THEORY & METHODS;            | Free(pay all overlength page charges $250,<br/>color charges, and any other charges and fees associated with publication of<br/>the manuscript) Above 10 pages | Average 8.1months<br/>(Monthly) | 6036/889=6.790 |
| 3. MEDICAL IMAGE ANALYSIS(MIA)                            | COMPUTER SCIENCE, ARTIFICIAL INTELLIGENCE;<br/><br/>COMPUTER SCIENCE, INTERDISCIPLINARY APPLICATIONS;<br/><br/>ENGINEERING, BIOMEDICAL;<br/><br/>RADIOLOGY, NUCLEAR MEDICINE & MEDICAL IMAGING; | RADIOLOGY, NUCLEAR MEDICINE & MEDICAL IMAGING; | Free(charge  $250 for Open access and offprints color figure) | (8 issues/year)<br/>5.4 months  | 1918/216=8.880 |
| 4. IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING<br/>(TBME) | ENGINEERING, BIOMEDICAL                                      | ENGINEERING, BIOMEDICAL                        | Free(charges $250 , such as: overlength  7 pages, OA)        | 3.0 months                      | 2470/550=4.491 |



# Week 6 Writing schedule

## 1. Task

æœŸæœ«æäº¤çš„æ–‡ç« å†™ä½œç±»å‹ï¼Œå¯é¢„è®¡çš„å›°éš¾å’Œè§£å†³æ–¹æ¡ˆï¼Œå†™ä½œæ—¶é—´å®‰æ’.

## 2. Target journal

ç›®æ ‡æœŸåˆŠï¼šMedical Image Analysis or IEEE Transactions On Medical Imagingï¼ˆä¸¤è€…éƒ½æ˜¯å·å¤§è®¡ç®—æœºå­¦ç§‘BåŒºã€å½±å“å› å­åˆ†åˆ«ä¸º8.880å’Œ7.816ï¼Œå±äºè®¡ç®—æœºåŒ»å­¦å›¾åƒé¢†åŸŸé¡¶åˆŠï¼‰

![1](https://wzwimg-1300620626.cos.ap-chengdu.myqcloud.com/githubimg/11.png)

<font size=2>Figure 1. ç›®æ ‡æœŸåˆŠåœ¨å·å¤§åˆ†çº§ç›®å½•çš„è¡¨æ ¼</font>

## 3. Writing schedule

æœŸæœ«æäº¤çš„æ–‡ç« å†™ä½œç±»å‹ï¼šArticle;

é¢„è®¡å›°éš¾å’Œè§£å†³æ–¹æ¡ˆï¼šé¢„è®¡å›°éš¾ï¼šè¯­æ³•ä¸Šç¬¦åˆè¯¥æœŸåˆŠæ ‡å‡†ã€æœ¯è¯­å•è¯æ˜¯å¦å‡†ç¡®ã€æ–¹æ³•åˆ›æ–°åº¦ã€Introductionçš„æ€»ç»“ç²¾ç‚¼ç¨‹åº¦ï¼›è§£å†³æ–¹æ¡ˆï¼šå¤šæ”¶é›†CNSå’Œç›®æ ‡æœŸåˆŠçš„å¥å­è¯­æ³•è¯æ±‡ï¼Œä¸“ä¸šåˆ›æ–°åº¦ä¸Šç”±å¯¼å¸ˆæŠŠå…³ï¼Œå…¶ä»–éå­¦æœ¯çš„éƒ¨åˆ†ï¼Œå¦‚Introductionä¹Ÿæ˜¯å¤šæ€»ç»“è¯¾å ‚ä¸Šå­¦ä¹ çš„æˆ–æœŸåˆŠä¸Šçœ‹åˆ°çš„å¥å­ã€‚

å†™ä½œæ—¶é—´å®‰æ’ï¼š11æœˆå®ŒæˆIntroductionéƒ¨åˆ†ï¼Œç”šè‡³ä¸€äº›æ€è·¯ï¼›

# Week 7 Introduction

## 1. Task

è¯»5ç¯‡åŠä»¥ä¸Šé¡¶åˆŠæˆ–ç›®æ ‡æœŸåˆŠçš„æ–‡ç« introductionéƒ¨åˆ†ï¼Œå¹¶å†™ä¸‹è‡ªå·±å¯¹è¯¥éƒ¨åˆ†åœ¨contents/logic/languageå‡ æ–¹é¢çš„é˜…è¯»æ”¶è·å’Œä½“ä¼šã€‚

## 2. Gaining

Overviewï¼šé€šè¿‡é˜…è¯»æ–‡ç« ï¼Œç„¶åçœ‹äº†ä¸€äº›æ•™ç¨‹ï¼Œæˆ‘å‘ç°ï¼šIntroduction éƒ¨åˆ†è¦**ç®€å•æ˜ç™½ï¼Œé€»è¾‘æ€§å¼ºï¼Œå±‚å±‚é€’è¿›ï¼Œä¸‰è€…ç´§å¯†ç»“åˆ**ã€‚ä¸‹é¢æ¥å¯¹contents/logic/languageå±•å¼€è®¨è®ºã€‚éƒ­è€å¸ˆç»“åˆå¸¸ç”¨çš„å†™ä½œé¡ºåºï¼šå…ˆIntroductionï¼ŒåMethodsã€Resultsã€Discussionã€Referenceï¼Œæœ€åæ‰Abstractã€Titleï¼Œä½œä¸šä¹ŸæŒ‰å†™ä½œçš„æ¬¡åºæ¥ï¼Œè¿™å‘¨æ˜¯Introductionã€‚

Contentï¼šIntroduction çš„å†…å®¹å°±æ˜¯è®ºæ–‡çš„ç ”ç©¶èƒŒæ™¯ä»¥åŠå¼•å‡ºï¼Œå†…å®¹è¦ç®€å•æ˜“æ‡‚ï¼Œç”¨è‡ªå·±çš„è¯è¯´å‡ºæ¥ã€‚1ï¼‰åœ¨å†™ä¹‹å‰ï¼Œè¦ç¡®å®šè‡ªå·±çš„**åˆ›æ–°ç‚¹**ã€‚è¿™äº›ä¸œè¥¿éœ€è¦**é€»è¾‘æçº²**æ¥è¿æ¥ï¼Œè¿™ä¸€æ­¥å¯ä»¥å‡å°‘å†™ä½œæ—¶é—´ï¼Œå†™ä¹‹å‰ç¡®ä¿è¦å’Œå¯¼å¸ˆæ²Ÿé€šï¼›2ï¼‰å†™çš„æ—¶å€™ï¼Œç´§ç´§å›´ç»•è¿‡å»**ç ”ç©¶çš„ç¼ºé™·**æ¥æå†™ï¼Œæ¸…æ™°åœ°å¯¹è‡ªå·±çš„ç ”ç©¶æ¥é˜è¿°æ€ä¹ˆ**è§£å†³è¿™äº›ç¼ºé™·**ã€‚æå‡ºè‡ªå·±çš„å·¥ä½œæ—¶ï¼Œä¸è¦æ‹”é«˜è‡ªå·±ï¼Œ**è´¬ä½**åˆ«äººã€‚è®ºæ–‡çš„è®ºç‚¹ä¸è¦å¤ªå¹¿ï¼ŒæŠ“ä½ä¸€ä¸ª**é‡ç‚¹**æ¥æ·±å…¥ï¼Œè®ºè¿°å¤ªå¹¿ä¼šè®©æ–‡ç« é‡ç‚¹ä¸å¤Ÿçªå‡ºã€‚

Logicï¼šä»å¾ˆä¹…â€œæ ¹â€ç ”ç©¶ï¼Œå¯ä»¥ä»æ—¶é—´çº¿å‡ºå‘ï¼ˆå¦‚ï¼šå¤å…¸åŠ›å­¦ â†’ è¿‘ä»£åŠ›å­¦ â†’ ç°ä»£ç‰©ç†ï¼‰ï¼Œä¹Ÿå¯ä»¥ä»å­¦ç§‘çš„ä¸åŒé€»è¾‘çº¿å‘å±•ã€‚

Languageï¼šè¡”æ¥è¯ä¸ä»å¥è¦å¾—ä½“ï¼Œå¤šç”¨è‹±è¯­ä¹ æƒ¯çš„å¥å¼ï¼Œä¼šè¿è´¯å¾ˆå¤šã€‚

## 3. Introduction äº”é‡å¥ğŸ¶

**å…·ä½“ä¾‹å­**ğŸŒ°ï¼š

è¿™é‡Œä»¥ä¸€ç¯‡ç¬”è€…æ–¹å‘çš„è®ºæ–‡ *A Deep Cascade of Convolutional Neural Networks for MR Image Reconstruction.* ä½œä¸ºä»‹ç»ï¼Œå¸Œæœ›è¿™ä¸ªæ€è·¯æ˜¯æ­£ç¡®çš„ã€‚

1ï¼‰ğŸµé¦–å…ˆæå‡ºç ”ç©¶é¢†åŸŸï¼šæ ¸ç£å…±æŒ¯çš„å›¾åƒé‡å»ºï¼ˆé‡‡é›†åŸå§‹æ•°æ®åˆ°æ„æˆå›¾åƒçš„è¿‡ç¨‹å«é‡å»ºï¼‰ã€‚In many clinical scenarios, medical imaging is an indispensable diagnostic and research tool. One such important modality is Magnetic Resonance Imaging (MRI), which is non-invasive and offers excellent resolution with various contrast mechanisms to reveal different properties of the underlying anatomy.  ï¼ˆ**æŒ‡å‡ºç ”ç©¶èŒƒå›´**ï¼‰

2ï¼‰ğŸµç„¶åï¼Œå›é¡¾äº†æ ¸ç£å…±æŒ¯çš„å‘å±•å†å²ï¼ŒæŒ‡å‡ºäº†æ ¸ç£å…±æŒ¯æˆåƒæ…¢çš„é€šç—…ã€‚åŒæ—¶ä¹Ÿæå‡ºäº†å„ä¸ªæ–¹æ³•æå‡ºæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ä½†æ˜¯è¿™ä¸ªé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œå½“åœ¨åŠ¨æ€ç£å…±æŒ¯å½“ä¸­ï¼Œè¿™ä¸ªé—®é¢˜å°¤ä¸ºçªå‡ºï¼Œç›®å‰çš„æ ¸ç£å…±æŒ¯æˆåƒæ—¶é—´ä¾æ—§æ˜¯ä¸ªé—®é¢˜ã€‚However,
MRI is associated with a slow acquisition process. This is because data samples of an MR image are acquired sequentially in k-space and the speed at which k-space can be traversed is limited by underlying MR physics. A long data acquisition procedures impose significant demands on patients, making the tool expensive and less accessible. One possible approach to accelerate the acquisition process is to undersample k-space, which in theory provides an acceleration rate proportional to a reduction factor of a number of k-space traversals required. However, undersampling in k-space violates the Nyquist-Shannon theorem and generates aliasing artefacts when the image is reconstructed. The main challenge in this case is to find an algorithm that takes into account the undersampling undergone and can compensate missing data with a-priori knowledge on the image to be reconstructed. 

Using Compressed Sensing (CS), images can be reconstructed from subNyquist sampling, assuming the following:  Â·Â·Â· Â·Â·Â· Using Compressed Sensing (CS), images can be reconstructed from subNyquist sampling, assuming the following:  Â·Â·Â· Â·Â·Â· ï¼ˆ**è¯´æ˜äº†ç ”ç©¶èƒŒæ™¯ï¼Œæå‡ºå­˜åœ¨çš„ä¸€ä¸ªé—®é¢˜**ï¼‰

3ï¼‰ğŸµéšåï¼Œä»‹ç»æ·±åº¦å­¦ä¹  Deep learningï¼Œå¹¶æŒ‡å‡ºDLä½œä¸ºMRIé‡å»ºæŠ€æœ¯å­˜åœ¨çš„ä¼˜åŠ¿ã€‚Recently, deep learning has been successful at tackling many computer vision
problems.   Â·Â·Â· Â·Â·Â·ï¼ˆ**ç¡®å®šç ”ç©¶ç›®æ ‡ï¼ŒæŒ‡å‡ºæœ¬ç ”ç©¶ç›®æ ‡çš„ä¼˜åŠ¿**ï¼‰

4ï¼‰ğŸµè€Œåï¼ŒæŒ‡å‡ºè‡ªå·±è¯¾é¢˜ç»„å‰æœŸåœ¨ Deep learning ä½œä¸ºæ ¸ç£å›¾åƒé‡å»ºçš„å·¥ä½œï¼Œå¹¶ç”±æ­¤å¼•å‡º Deep learning åœ¨æ ¸ç£å…±æŒ¯å›¾åƒé‡å»ºé¢†åŸŸå¹¶æœªå¹¿æ³›ç ”ç©¶ã€‚ï¼ˆ**æŒ‡å‡ºè‡ªå·±è¯¾é¢˜ç»„ç›¸å…³çš„å·¥ä½œï¼Œå¹¶æå‡ºè¿™äº›å·¥ä½œä»ç„¶å­˜åœ¨é—®é¢˜æˆ–è€…å±€é™**ï¼‰

5ï¼‰ğŸµæœ€åï¼Œæå‡ºæœ¬æ–‡çš„ç ”ç©¶é‡ç‚¹æ˜¯ Deep learning åœ¨å›¾åƒé‡å»ºé¢†åŸŸçš„ä¸€äº›å‘ç°ã€‚ç»“åˆå­—å…¸å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ï¼Œèƒ½å®ç°æ ¸ç£å…±æŒ¯å›¾åƒçŸ­æ—¶é—´æˆåƒï¼Œå¹¶ä¸”æœ‰é«˜çš„å›¾åƒè´¨é‡ã€‚ï¼ˆ**æå‡ºæœ¬æ–‡ç ”ç©¶çš„é‡ç‚¹ï¼Œé‡‡ç”¨çš„æ–¹æ³•ï¼Œå¾—å‡ºç»“è®º**ï¼‰

**References**

Schlemper, Jo, Jose Caballero, Joseph V. Hajnal, Anthony Price, and Daniel Rueckert. 2017. â€œA Deep Cascade of Convolutional Neural Networks for MR Image Reconstruction.â€ In *Information Processing in Medical Imaging*, edited by Marc Niethammer, Martin Styner, Stephen Aylward, Hongtu Zhu, Ipek Oguz, Pew-Thian Yap, and Dinggang Shen, 647â€“58. Lecture Notes in Computer Science. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-59050-9_51.



# Week 8 Results 

## 1. Task

ã€ç¬¬å…«å‘¨å­¦ä¹ ä»»åŠ¡ã€‘å¤§å®¶å¥½ï¼Œæœ¬å‘¨å­¦ä¹ å†…å®¹å¦‚ä¸‹ï¼š
1ã€Writing Journal. é˜…è¯»è‡ªå·±é€‰å®šæ–‡ç« çš„Resultså¹¶è®°å½•æ”¶è·å’Œä½“ä¼šï¼Œä¸‹æ¬¡ä¸Šè¯¾å¸¦ä¸Šã€‚ï¼ˆæ³¨ï¼šå¯ä»¥å‚è€ƒè¯¾ç¨‹èµ„æ–™"Week 8 Results - 8.Tasks "ä¸­çš„æ¡ç›®æ¥è®°å½•ï¼Œä¹Ÿå¯è‡ªè¡Œå®‰æ’ã€‚ï¼‰
2ã€ä¸»é¢˜é˜…è¯»ï¼šDiscussionã€‚å‚è€ƒä¹¦ç›®å¦‚ä¸‹ï¼š
ï¼ˆ1ï¼‰Section 2, chapter 9 (Margaret Cargill & O'Connor Patrick. Writing Scientific Research Articles: Strategy and Steps. 2nd Edition. Wiley-Blackwell. 2013.)
ï¼ˆ2ï¼‰Chapter 18 (Adrian Wallwork. English for Writing Research Paper (2nd Edition), Springer. 2016ï¼‰
ï¼ˆ3ï¼‰PP363-378 (Swales J., Feak C. Academic Writing for Graduate Students: Essential Tasks and Skills. Michigan, ELT. 2012)

## 2. Gaining

è¯¥å†™åœ¨Material & Methodç”šè‡³discussionéƒ¨åˆ†çš„ä¿¡æ¯ç½—åˆ—åœ¨è¿™é‡Œã€‚è¿™é‡Œæ˜¯æ–‡ç« çš„ â€œå¿ƒè„â€ ï¼Œå¦‚å›¾1ï¼Œè¿™éƒ¨åˆ†çš„æå†™åº”è¯¥å°½å¯èƒ½åœ°æ¸…æ™°ç®€æ˜åœ°æè¿°ç»“è®ºã€‚ç¬¬ä¸€ç§æ–¹æ³•æ˜¯ä»‹ç»ç»“æœï¼Œå¹¶åœ¨æ­£å¼è¿›å…¥Discussionéƒ¨åˆ†ä¹‹å‰ï¼Œæ·»åŠ ä¸€ä¸ªç®€çŸ­çš„æ€»ç»“ã€‚å¯¹äºæ¯”è¾ƒç›´æ¥å’Œç®€å•ï¼Œå¹¶å…·æœ‰è¿ç»­æ€§çš„ç ”ç©¶å‹è®ºæ–‡ï¼Œè¿™ç§å†™æ³•æ˜¯éå¸¸å¸¸è§çš„ã€‚ç¬¬äºŒç§æ–¹æ³•æ˜¯å…ˆæå‡ºä¸€ä¸ªéƒ¨åˆ†çš„ç»“æœï¼Œç„¶åæ¥ç»™å‡ºä¸€ä¸ªæ€»ç»“ã€‚æ¥ä¸‹æ¥å†ç®€è¦è®¨è®ºä¸‹ä¸€ä¸ªéƒ¨åˆ†ã€‚ è¿™ç§æ–¹å¼é€šå¸¸ç”¨äºè¾ƒé•¿çš„è®ºæ–‡ï¼Œè€Œä¸”æ¥ä¸‹æ¥çš„Discussionéƒ¨åˆ†ä¹Ÿä¼šéµå¾ªç›¸åŒçš„ç»“æ„ã€‚

![1](https://wzwimg-1300620626.cos.ap-chengdu.myqcloud.com/githubimg/clipboard_20191211051959.png)

Figure 1. A type structure of article.

**åƒä¸‡ä¸è¦ç®€å•ç½—åˆ—å›¾æ ‡**ã€‚è¿™é‡Œç¬”è€…æ³¨æ„åˆ°Resultséƒ¨åˆ†ç»™å‡ºå¤ªå¤šçš„ä¿¡æ¯ï¼Œ â€œtoo much informationâ€ã€‚Resultséƒ¨åˆ†ä¸ä»¥ä»»ä½•æ–¹å¼è§£é‡Šç»“æœï¼Œè¿™éƒ¨åˆ†åº”è¯¥åœ¨Discussioné‡Œå‘ˆç°ã€‚ Resultséƒ¨åˆ†åº”è¯¥å°è¯•ä¸å¸¦æœ‰ä»»ä½•è§£é‡Šæˆ–è€…è¯„ä»·å£æ°”çš„æ¥å™è¿°å‘ç°ï¼Œè€Œä¸æ˜¯ç›´æ¥å¿«é€Ÿè¿›å…¥Discussionéƒ¨åˆ†ã€‚

aï¼‰è®ºæ–‡æ’°å†™Resultsçš„è¦æ±‚æ˜¯ç¿”å®å‡†ç¡®ã€‚å‡†ç¡®æ˜¯ç»“æœå¿…é¡»æ˜¯çœŸå®çš„ï¼Œä¸èƒ½ä¼ªé€ å’Œç¯¡æ”¹ï¼›

bï¼‰ç»“æœæä¾›è¡¨å’Œå›¾ï¼›

cï¼‰Resultså’ŒDiscussionåˆ†å¼€å†™æ—¶ï¼ŒResultséƒ¨åˆ†å°½é‡ä¸è¦æ¶‰åŠå¯¹ç»“æœçš„è¯„è®ºï¼Œæœ€å¤šæ˜¯æ€»ç»“é™ˆè¿°ç»“æœå°±å¯ä»¥äº†ï¼›

dï¼‰å¤§å¤šè¦æä¾›ç»Ÿè®¡ç»“æœã€‚æ–¹å·®åˆ†æçš„ç»“æœå½¢å¼è¦æ ¹æ®åˆŠç‰©çš„æ ¼å¼ç»™å‡ºã€‚

å¯¹äºæ’°å†™ï¼Œæ¸…æ™°ç›®æ ‡ï¼Œå‡†ç¡®åœ°ä¼ è¾¾ä»¥ç›®æ ‡ä¸ºæ ¸å¿ƒçš„æ•°æ®ä¿¡æ¯ï¼Œç²¾ç¡®è€Œç´§å‡‘çš„çŸ­è¯­å’Œå¥å­æ˜¯æœ€æœ‰æ•ˆçš„ã€‚åœ¨Resultséƒ¨åˆ†ä¸­è¿›è¡Œæ¸…æ™°ä¸”ä»¤äººä¿¡æœçš„å†™ä½œæ®µè½ï¼Œåº”åŒ…æ‹¬é—®é¢˜ï¼Œå®éªŒæ–¹æ³•ï¼Œç»“æœå’Œå°å‘ç°ï¼ˆAnswerï¼‰ã€‚

## 3. Results å››é‡å¥ ğŸ¶

**å…·ä½“ä¾‹å­**ğŸŒ°ï¼š

è¿™é‡Œä»¥ä¸€ç¯‡ç¬”è€…æ–¹å‘çš„è®ºæ–‡ *A Deep Cascade of Convolutional Neural Networks for MR Image Reconstruction.* ä½œä¸ºä»‹ç»ï¼Œå¸Œæœ›è¿™ä¸ªæ€è·¯æ˜¯æ­£ç¡®çš„ã€‚

1ï¼‰ğŸµé¦–å…ˆæå‡ºé—®é¢˜ï¼šé€šè¿‡ç”¨ç®€çŸ­çš„å¥å­æˆ–çŸ­è¯­è¯´æ˜ï¼Œæ‰§è¡Œç‰¹å®šå®éªŒçš„ç›®çš„æ˜¯è¦è§£å†³ä»€ä¹ˆé—®é¢˜ï¼›The means of the reconstruction errors across 10 subjects are summarised in
Table 1. 

2ï¼‰ğŸµç„¶åå®éªŒæ–¹æ³•ï¼šåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸åº”é‡å¤å®éªŒç»†èŠ‚ï¼Œå»ºè®®å°†æ–¹æ³•ï¼ˆå°½é‡ç®€æ´æ˜äº†ï¼‰ä¸ç»“æœè”ç³»èµ·æ¥ï¼Œå¯ä½¿ç”¨è¿™ä¸¤ç§å¥å‹ç»“æ„æ¨¡å¼æ¥é˜è¿°ï¼šä¸€æ˜¯ä½¿è¯¥æ–¹æ³•æˆä¸ºå¥å­çš„ä¸»è¯­ï¼ŒäºŒæ˜¯ä½¿ç”¨è½¬æ¢çŸ­è¯­æˆ–å¥å­ä»¥åŠä¸»å¥ä¸­çš„ç»“æœæ¥è¯´æ˜æ–¹æ³•ã€‚While training CNN is time consuming,
once it is trained, the inference can be done extremely quickly on a GPU.  Â·Â·Â· Â·Â·Â·ï¼ˆ**è¿™é‡Œä½œè€…å®‰æ’åœ¨æœ€åä¸€æ®µ**ï¼‰

3ï¼‰ğŸµéšåç»“æœï¼šç»“æœæ˜¯å…³äºé‡è¦æ•°æ®çš„æ–‡æœ¬æè¿°ï¼Œå¹¶èµ‹äºˆæ•°æ®æ„ä¹‰ï¼ŒåŒæ—¶ï¼Œå¾—ç¡®ä¿æ˜¯åˆä¹é€»è¾‘çš„ã€‚For both 3-fold and 6-fold acceleration, one can see that CNN consistently outperformed DLMRI, and that the standard deviation of the error made by CNN was smaller. The reconstruction from 3-fold acceleration can be found in Fig. 2. It can be seen that the CNN approach produced a smaller overall error. The CNN reconstruction produced a more homogeneous reconstruction. On the other hand, DLMRI gave a blocky reconstruction. In some cases, both CNN and DLMRI suffered from small losses of important anatomical structures in their reconstructions (orange), but CNN was able to recover more details (red). The reconstructions from 6-fold acceleration is in Fig. 3.   

4ï¼‰ğŸµæœ€åå°å‘ç°ï¼ˆAnswerï¼‰ï¼šåœ¨æœ€åä¸€ä¸ªå¥å­ä¸­ï¼Œå°†è¯¥æ®µè½çš„å®éªŒç»“æœä¸é—®é¢˜è”ç³»èµ·æ¥ï¼Œæ¥ä¸ªå°å°å‰åå‘¼åº”ï¼Œæˆ–å¼•å‡ºä¸‹ä¸€ä¸ªç»“æœï¼Œå……å½“è¿‡æ¸¡ã€‚ä½†è¿™ä¸åŒ…æ‹¬å¯¹å®éªŒç»“æœçš„å«ä¹‰çš„å®Œæ•´è®¨è®ºã€‚Although both methods suffered from significant loss of structures (orange), CNN was still capable of better preserving the texture than DLMRI (red). On the other hand, DLMRI created extremely block-like artefacts due to over-smoothing. 6Ã— undersampling for these  Â·Â·Â· Â·Â·Â·

# Week 10 Discussion 

## 1. Task

ã€ç¬¬åå‘¨å­¦ä¹ ä»»åŠ¡ã€‘å¤§å®¶å¥½ï¼Œæœ¬å‘¨å­¦ä¹ å†…å®¹å¦‚ä¸‹ï¼š
1ã€Writing Journal. é˜…è¯»é€‰å®šæ–‡ç« çš„Discussionå¹¶è®°å½•æ”¶è·å’Œä½“ä¼šï¼Œä¸‹æ¬¡ä¸Šè¯¾å¸¦ä¸Šã€‚ï¼ˆæ³¨ï¼šå¯å‚è€ƒè¯¾ç¨‹èµ„æ–™"Week 10 Discussion - 9.Tasks "ä¸­çš„æ¡ç›®æ¥è®°å½•ï¼Œä¹Ÿå¯è‡ªè¡Œå®‰æ’ã€‚ï¼‰
2ã€ä¸»é¢˜é˜…è¯»ï¼šTitile, Abstract, Conclusionã€‚å‚è€ƒä¹¦ç›®å¦‚ä¸‹ï¼š
ï¼ˆ1ï¼‰Chapter 12, 13, 19 (Adrian Wallwork. English for Writing Research Paper (2nd Edition), Springer. 2016ï¼‰
ï¼ˆ2ï¼‰Chapter 10, 11 (Margaret Cargill & O'Connor Patrick. Writing Scientific Research Articles: Strategy and Steps. 2nd Edition. Wiley-Blackwell. 2013.)
ï¼ˆ3ï¼‰Unit 5: Writing summaries (Swales J., Feak C. Academic Writing for Graduate Students: Essential Tasks and Skills. Michigan, ELT. 2012)

## 2. Reviewing in class

### How should we structure the Discussion?

The Discussion should answer the following questions, and possibly in the following order. You can thus use the answers to structure your Discussion. This gives you a relatively easy template to follow.

1. What are my most important findings?

2. Do these findings support what I set out to demonstrate at the beginning of the paper?

3. How do my findings compare with that others have found? How consistent are they?

4. What is my personal interpretation of my findings?

5. What other possible interpretations are there?

6. What are the limitations of my study? What other factors could have influenced my findings? Have I reported everything that could make my findings invalid?

7. Do any of the interpretations reveal a possible flaw (i.e. defect, error) in my experiment?

8. Do my interpretations contribute some new understanding of the problem that I have investigated? In which case do they suggest a shortcoming in, or an advance on, the work of others?

9. What external validity do my findings have? How could my findings be generalized to other areas?

10. What possible implications or applications do my findings have? What support can I give for such implications?

11. What further research would be needed to explain the issues raised by my findings? Will I do this research myself or do I want to throw it open to the community?

    

## 7. Good examples

### 7.1 (4)Short discussion

 We have delineated the spatiotemporal dynamics, genomic landscape and functional consequences of naive CD8$^+$ T cells undergoing intrahepatic priming (Extended Data Fig. [10](https://www.nature.com/articles/s41586-019-1620-6#Fig14)). We showed that hepatocellular presentation leads to a CD8$^+$ T cell dysfunction that is distinct from T cell alterations reported in other viral infections and cancer and, as such, is not readily responsive to anti-PD-L1 treatment. As immune checkpoint inhibitors are beginning to be tested in patients persistently infected with HBV, the results reported here should help to interpret the outcome of those studies and eventually inform the design of modified trials in selected cohorts of patients. Our data identify IL-2 as a potent immunotherapeutic that can rescue CD8$^+$ T cells rendered dysfunctional by hepatocellular priming. Thus, IL-2-based strategies should be considered for the treatment of chronic HBV infection. ï¼ˆç¬¬ä¸€å¥ç‚¹é¢˜ã€‚ç¬¬äºŒå¥ç»™å‡ºç»“æœã€‚ï¼‰

\- "Dynamics and genomic landscape of CD8$^+$â€‹ T cells undergoing hepatic priming", *Nature*. 2019-10-08.

çŸ­è®¨è®ºæ¯”è¾ƒæ³¨é‡çªå‡ºç»“æœï¼Œæ€»å…±æœ‰137ä¸ªå•è¯ã€‚

### 7.2 (5)Long discussion

`One striking aspect of our atlas is that`$^{[1][2]}$ the distribution of semantically selective areas is relatively symmetrical across the two cerebral hemispheres. `This finding is inconsistent with`$^{[3]}$ human lesion studies that support the idea that semantic representation is lateralized to the left hemisphere[13](https://www.nature.com/articles/nature17637#ref13). `However`, many fMRI studies of semantic representation find only modest lateralization[1](https://www.nature.com/articles/nature17637#ref1) and one study that used narrative stories found highly bilateral results similar to ours[2](https://www.nature.com/articles/nature17637#ref2). (å‰é¢è¿™å¥è¯ä¸¾ä¾‹å‡ºäº†å’Œè‡ªå·±å®éªŒç›¸åŒå’Œä¸åŒçš„ä¾‹å­)`This suggests that` right hemisphere areas may respond more strongly to narrative stimuli than to the words and short phrases used in most studies. `Still`\*, `more research will be needed to determine` what roles these left- and right-hemisphere semantic areas have in language comprehension.ï¼ˆè¿™å¥è¯ååˆ†æ–­ç„¶ï¼Œè‚¯å®šã€‚è¿™æ˜¯å¯¹è‡ªå·±ç»“æœçš„è®¨è®ºã€‚å…¶ä¸­ï¼Œstillè¿™ä¸ªè¯è¯­ç”¨çš„å¾ˆåœ°é“å’Œç²¾é«“ã€‚æ•´ä¸ªç»“æ„æ˜¯å±‚æ¬¡é€’è¿›çš„ï¼šå…ˆç»™å‡ºä¸»è¦å‘ç°çš„ç»“æœï¼›ç„¶åä»ä¸åŒäºäººä»¬è®¤ä¸ºè¯­è¨€çš„å·¦è„‘å•è¾¹ä¾§åŒ–--æœ‰ç ”ç©¶è®¤ä¸ºé€‚åº¦ä¾§åŒ–--æœ‰ç ”ç©¶è®¤ä¸ºä¸ä»–ä»¬ç›¸ä¼¼çš„é«˜åº¦åŒè¾¹ä¾§åŒ–ï¼›ç»™å‡ºè®¨è®ºï¼Œå†ç”¨Stillç»™å‡ºè¿›ä¸€æ­¥çš„ä¸œè¥¿ã€‚è¿™ä¸€æ®µæ˜¯ä¸»è¦ç ”ç©¶ç»“æœçš„é‚£æ–¹é¢ï¼‰

`Another interesting aspect of these results is that` the organization of semantically selective brain areas seems to be highly consistent across individuals. `This might suggest` that innate anatomical connectivity or cortical cytoarchitecture constrains the organization of high-level semantic representations[28](https://www.nature.com/articles/nature17637#ref28),[29](https://www.nature.com/articles/nature17637#ref29). `It is also possible that` this is owing to common life experiences of the subjects, all of whom were raised and educated in Western industrial societies. `Future studies that include subjects from more diverse backgrounds will be needed to determine` how much of this organizational consistency reflects innate brain structure versus experience.ï¼ˆmightã€possibleè¿™äº›è¯æ±‡çš„è¿ç”¨ï¼Œæ˜¾å‡ºè¿™ä¸ªæ®µè½ååˆ†ç¼“å’Œï¼Œç”±äºæ²¡æœ‰å¤§è§„æ¨¡çš„è°ƒæŸ¥ã€‚è¿™ä¸€æ®µæ˜¯å¸¦æœ‰çŒœæµ‹çš„ç»“æœçš„é‚£æ–¹é¢ï¼‰

`One` `limitation`\*ï¼ˆé™åˆ¶æ€§è¯è¯­ï¼‰ `of PrAGMATiC as used here is that` each area is assumed to be functionally homogeneous. `This is a common assumption` in the design and analysis of many neuroimaging studies[30](https://www.nature.com/articles/nature17637#ref30). `However`, many cortical maps, including semantic maps in visual cortex[14](https://www.nature.com/articles/nature17637#ref14), `seem to contain` smoothly changing gradients of representation. `It should be possible to modify` the PrAGMATiC algorithm to model functional gradients explicitly. `This will provide an objective tool for determining` whether the semantic maps found here are best described as homogeneous areas or as gradients.ï¼ˆè¿™ä¸€æ®µè®²å±€é™æ€§ã€‚å¹¶ä¸”è¯´æ˜äº†åŸå› å’Œå¯æ”¹è¿›æ–¹æ³•ã€‚æ³¨æ„æ’å…¥å¥ã€‚ä»åŒè´¨æ€§å‡è®¾è°ˆè®ºåˆ°ä¼¼ä¹æœ‰æ¢¯åº¦çš„ä¸åŒã€‚æå‡ºäº†ä¿®æ”¹æ¨¡å‹ï¼Œæœ€åç»™å‡ºè¯•éªŒï¼Œåšå‡ºè¯•éªŒèƒ½åˆ¤æ–­åŒè´¨æ¨¡å‹è¿˜æ˜¯æ¸å˜æ¨¡å‹å¥½ã€‚ï¼‰

`Data-driven approaches are commonplace in studies of` human neuroanatomy[31](https://www.nature.com/articles/nature17637#ref31) and resting state networks[26](https://www.nature.com/articles/nature17637#ref26),[32](https://www.nature.com/articles/nature17637#ref32), `but`\* `are only beginning to be used`\* in functional imaging[14](https://www.nature.com/articles/nature17637#ref14),[15](https://www.nature.com/articles/nature17637#ref15).` Our study demonstrates` the power and efficiency of data-driven approaches for functional mapping of the human brain. `Although` our experiment used a simple design in which subjects only listened to stories, the data were rich enough to produce a comprehensive atlas of semantically selective areas. `Furthermore`, `our data-driven framework is quite general`\*. Other properties of language can be mapped (even in this same data set) by using feature spaces that reflect phonemes, syntax and so on. Complex semantic models that incorporate information beyond word co-occurrence can be tested and compared quantitatively. `The generalizability of these models can also be tested by` using stimuli beyond autobiographical stories. `It is sometimes difficult to synthesize the results of` data-driven experiments with those from hypothesis-driven experiments, `but future methodological and theoretical developments should help to bridge this divide`\*. `We expect` that the semantic atlas presented here will be useful for many researchers investigating the neurobiological basis of language. We `also` expect that this atlas can be refined and expanded by incorporating results from future studies. `To facilitate this`, we have creatsed a detailed interactive version of the semantic atlas that can be explored online at http://gallantlab.org/huth2016.ï¼ˆç»“å°¾æ®µè½ã€‚ç¬¬ä¸€å¥æ€»ç»“ä½¿ç”¨çš„æ•°æ®é©±åŠ¨æ–¹æ³•åœ¨æˆç†Ÿé¢†åŸŸå’Œåˆšå‘å±•çš„é¢†åŸŸã€‚but areç”¨çš„å¾ˆç²¾é«“ã€‚ç´§æ¥ç€è¯´æ˜äº†æœ¬æ–‡çš„æ•°æ®é©±åŠ¨æ–¹æ³•åœ¨è¿™ä¸ªé¢†åŸŸååˆ†å¥½ã€‚Althoughåˆç´§æ€¥è½¬æŠ˜è¯´æ˜äº†æœ¬æ–¹æ³•æ˜¯æ¯”è¾ƒç®€å•çš„ï¼Œä½†å¾ˆæœ‰ç”¨ã€‚Futhermoreï¼Œå¼ºè°ƒäº†é€šç”¨æ€§ï¼Œè§£é‡Šå¹¶ä¸”ä¸¾ä¾‹ã€‚æ­¤å¤–æå‡ºä¸€äº›è¯¥ç†è®ºæ˜¯å¯è¡¥å……å¾—ï¼Œå¹¶ä¸”åœ¨å°†æ¥å¯ä»¥å‘å±•ï¼šbridge this divideã€‚æå‡ºäº†ä¸€äº›åŸºäºæ­¤æ›´è¿œç ”ç©¶çš„å¸Œæœ›ï¼šWe expectï¼Œand also expectã€‚åŒºåˆ«ä¸¤è€…expectçš„ä¸åŒã€‚æœ€åç»™å‡ºèµ„æºä¸æ•°æ®ã€‚ï¼‰

\-  â€œNatural speech reveals the semantic maps that tile human cerebral cortex,â€ *Nature*, 2016-04-28.

è¿™ç¯‡æ–‡ç« çš„è®¨è®ºéƒ¨åˆ†ï¼Œæœ‰ä¸‰ä¸ªé˜…è¯»çš„å¥½å¤„ï¼Œæ€»å…±558ä¸ªå•è¯ã€‚ï¼ˆ1ï¼‰çªå‡ºäº†æœ¬æ–‡ç¬¬2éƒ¨åˆ†çš„æ¯ä¸ªç‚¹ï¼›ï¼ˆ2ï¼‰è·¨å­¦ç§‘ï¼›ï¼ˆ3ï¼‰é•¿è®¨è®ºã€‚ç”¨çš„å¥½çš„çŸ­è¯­è¿™æ ·æ ‡æ³¨ï¼š`One striking aspect of our atlas is that`$^{[1][2]}$ ï¼Œå…¶ä¸­[1] [2]æŒ‡çš„æ˜¯åœ¨ç¬¬äºŒèŠ‚Reviewing in classä¸­å¯¹åº”çš„è®¨è®ºæ–¹æ³•ã€‚ç”¨çš„æå¥½çš„è¿è¯æˆ–çŸ­è¯­ç”¨ \* æ˜Ÿå·è¿›è¡Œæ ‡æ³¨ï¼š`Still`\*ã€‚è¿™äº›è¯è¯­ä¸çŸ­è¯­éƒ½å¿…é¡»è¿›å…¥ä¸ªäººçš„å­¦æœ¯è‹±è¯­å†™ä½œè¯­æ–™åº“ï¼ˆå› ä¸ºå®åœ¨å¤ªå¥½ç”¨äº†ï¼‰ã€‚å¹¶ä¸”åœ¨ç¬¬ä¸€æ®µçš„æ•…äº‹æƒ…èŠ‚æ˜¯ï¼Œï¼ˆ1ï¼‰ä»–ä»¬çš„ç ”ç©¶æ–¹å‘ï¼›ï¼ˆ2ï¼‰æ€ä¹ˆç¡®å®šè¿™ä¸ªç ”ç©¶æ–¹å‘çš„ã€‚

## 9. After Class: Tasks

1. Writing Journal. é˜…è¯»é€‰å®šæ–‡ç« çš„Discussionå¹¶è®°å½•æ”¶è·å’Œä½“ä¼šï¼Œä¸‹æ¬¡ä¸Šè¯¾å¸¦ä¸Šã€‚ï¼ˆæ³¨ï¼šå¯å‚è€ƒè¯¾ç¨‹èµ„æ–™"Week 10 Discussion - 9.Tasks "ä¸­çš„æ¡ç›®æ¥è®°å½•ï¼Œä¹Ÿå¯è‡ªè¡Œå®‰æ’ã€‚ï¼‰

2. ä¸»é¢˜é˜…è¯»ï¼šTitile, Abstract, Conclusionã€‚å‚è€ƒä¹¦ç›®å¦‚ä¸‹ï¼š

   - ï¼ˆ1ï¼‰Chapter 12, 13, 19 (Adrian Wallwork. English for Writing Research Paper (2nd Edition), Springer. 2016
   - ï¼ˆ2ï¼‰Chapter 10, 11 (Margaret Cargill & O'Connor Patrick. Writing Scientific Research Articles: Strategy and Steps. 2nd Edition. Wiley-Blackwell. 2013.)
   - ï¼ˆ3ï¼‰Unit 5: Writing summaries (Swales J., Feak C. Academic Writing for Graduate Students: Essential Tasks and Skills. Michigan, ELT. 2012)  

3. æœŸæœ«å®‰æ’
   - week15ï¼šæäº¤Final exam
   - week16-17ï¼šOne On One
   - week18-19ï¼šè€ƒè¯•ï¼Œå¼€å·

## 10. Homeworks

### 10.1 Notices that I must do in reading the discussion of a paper

1. Read your selected articles and examine the following questions. What moves can you identify in thr Discussion section? For example:

   - Move1-Backgroud information (research purposes, theory, methodology, optinal);

   - Move2-Summarizing and reporting key results (obligatory);

   - Move3-Commenting on the key results (making claims, explaining the results, comparing the new work with the previous studies, offering alternative explanations);

   - Move4-Stating the limitations of the study (optional, but probable in some fields);

   - Move5-Making recommendations for future implementation and/or for future research (optional);

2. Note the words or phrases of generality. In the Discussion section, a common device is to use one of the following "phrases of generality". For example:

   Overall / In general / On the whole / In the main / With ... exception(s);

   The overall results indicate..., / The results indicate, overall, that..., / With one exception, the experimental samples resisted...

3. Limitations in Discussion. Here are some typical formulations for stating limitations in one's research scope. For example: It should be noted that this study has been primarily concerned with ..., / This analysis has concentrated on ..., / The findings of this study are restricted to ..., /This study has addressed only the question of ...,/ We would like to point out that we have not ...

   Here are some typical openings for statements that firmly state that certain conclusions should not be drawn. For example: However, the findings do not simply...,/ The results of this study cannot be taken as evidence for ...,/ Unfortunately, we are unable to determine from this data ...,/ The lack of ... means that we cannot be certain ...,/ Notwithstanding its limitations, this study does suggest ...,/ Despite its preliminary character, the research reported here would seem to indicate ...,/ However exploratory, this study may offer some insight into ...,/

4. What about the length of sentences in Discussion. Long or short? How many words in long sentences?

### 10.2 The discussion of 1st paper (Nat Mach Intell, Jun. 2019)

The proposed MAP-NN, enhanced by the radiologist in the loop, performs favourably or comparably relative to the clinically used iterative reconstruction methods implemented by the three leading CT vendors. Once the MAP-NN is trained, the DL-based denoising process is highly efficient (about 100 slices per second per mapping depth) and easy to use in clinical practice, while iterative reconstruction techniques are time-consuming and subject to significant artefacts.ï¼ˆä¸åŒäº 7.2 (5)Long discussion é‡Œé¢çš„å¤šä¸ªå¥å­çš„è®¨è®ºï¼Œæœ¬æ–‡ç¬¬ä¸€æ®µåªç”¨äº†ä¸¤ä¸ªå¥å­ï¼Œè€Œä¸”è¿˜æ˜¯é•¿å¥ã€‚å¾ˆæ˜¯å¥‡æ€ªã€‚ç¬¬ä¸€å¥ç»™å‡ºäº†ç›¸æ¯”è¿­ä»£ç®—æ³•çš„æ•ˆæœï¼Œç¬¬äºŒå¥ç»™å‡ºäº†ç›¸æ¯”çš„ä¸¤ä¸ªä¼˜ç‚¹ï¼šé€Ÿåº¦å’Œä¼ªå½±ã€‚åœ¨ç¬¬ä¸€å¥å°±æåˆ°äº†radiologistçš„å¸®åŠ©ï¼Œè¯æ˜å…¶ä½œç”¨å¾ˆå¤§ã€‚è¿™æ®µç»™å‡ºäº†å¯¹æ¯”äºè¿­ä»£ç®—æ³•çš„æ•ˆæœã€‚ï¼‰

Compared to previously published DL-based denoising networks[14](https://www.nature.com/articles/s42256-019-0057-9#ref-CR14),[15](https://www.nature.com/articles/s42256-019-0057-9#ref-CR15),[16](https://www.nature.com/articles/s42256-019-0057-9#ref-CR16),[17](https://www.nature.com/articles/s42256-019-0057-9#ref-CR17),[19](https://www.nature.com/articles/s42256-019-0057-9#ref-CR19),[20](https://www.nature.com/articles/s42256-019-0057-9#ref-CR20),[21](https://www.nature.com/articles/s42256-019-0057-9#ref-CR21),[22](https://www.nature.com/articles/s42256-019-0057-9#ref-CR22),[23](https://www.nature.com/articles/s42256-019-0057-9#ref-CR23), which learn the denoising mapping from images collected at a specific low-dose setting to their NDCT counterparts, our MAP-NN can be viewed as a significant refinement and a major extension that learns not only intermediate denoised images through multiple CLONE stages but also the associated noise reduction direction. The number of CLONE modules, also known as the mapping depth, is a key parameter, and the radiologists have the best judgement regarding the selection of an optimal mapping depth in a task-specific fashion. MAP-NN with CLONEs provides a cost-effective and user-friendly interface between DL and radiologists, enabling mixed/augmented intelligence beyond what standalone DL could achieve. We provide more details about the differences between the conventional denoising model and the proposed progressive denoising model in Supplementary Notes [1](https://www.nature.com/articles/s42256-019-0057-9#MOESM1) and [2](https://www.nature.com/articles/s42256-019-0057-9#MOESM1).ï¼ˆLDCT, Low dose CTï¼ŒNDCTï¼ŒNormal dose CTã€‚è¿™æ®µç»™å‡ºäº†ç›¸æ¯”ä¹‹å‰çš„ç¥ç»ç½‘ç»œæ–¹æ³•çš„å¯¹æ¯”ã€‚å¹¶ä¸”è¯´æ˜å’Œä¹‹å‰çš„NNä¸åŒçš„ç‰¹ç‚¹ï¼šsignificantã€majorã€‚æ¥ç€å…·ä½“è®²äº†æœ¬æ–‡æ–¹æ³•çš„mapping depthå¯¼è‡´çš„ä¸åŒï¼Œé©¬ä¸Šæ¥ä¸Šradiologistçš„å¸®åŠ©æ˜¯bestã€‚é©¬ä¸Šåˆå¼ºè°ƒäº†MAP-NNçš„æ˜“ç”¨æ€§ã€‚æœ€åç»™å‡ºäº†é™„ä»¶ç»†èŠ‚ã€‚è¿™æ®µç»™å‡ºäº†ç›¸æ¯”ä¹‹å‰çš„ç¥ç»ç½‘ç»œæ–¹æ³•çš„å¯¹æ¯”ï¼Œå¹¶ç»™å‡ºäº†ä¸€ä¸ªé‡è¦ç»†èŠ‚ï¼Œradiologistã€‚ï¼‰

Our MAP-NN systematically demonstrates that the DL approach can provide a similar or better image quality in terms of structural fidelity and noise suppression as commercial iterative reconstruction (IR)  methods performing image reconstruction directly from raw data. Most importantly for clinical use, the DL approach is computationally much more efficient than IR. The DL approach can thus already effectively compete with IR solutions, and potentially replace the IR approach. Furthermore, because DL methods can be vendor agnostic, institutions that have CT scanners of various brands and from different vendors can utilize the MAP-NN model to produce similar image appearances, which is not possible with commercial IR techniques. Even though all reconstruction and processing algorithms are commercial products, our post-processing algorithm can be embedded within image viewer software, which is independent of any vendor. Currently, unique changes in image appearance are associated with vendor-specific reconstruction programs. This is an obstacle for large-scale radiomics studies, and could be streamlined using DL techniques in the future.ï¼ˆ structural fidelityï¼šç»“æ„ä¿çœŸåº¦ã€‚è¿™æ®µæ˜¯å¯¹ä¸Šé¢ä¸¤æ®µçš„æ€»ç»“ã€‚ä¹Ÿç‚¹é¢˜ç›®äº†ã€‚ç¬¬ä¸€å¥ç›´æ¥è¯´æ˜æ•ˆæœï¼Œç¬¬ä¸€å¥å¾ˆé•¿ã€‚ç„¶åè®¨è®ºäº†DLæ–¹æ³•æ—©å·²è¾¾åˆ°IRæ–¹æ³•æ•ˆæœã€‚å¥½å¤„ï¼šä»ç³»ç»Ÿæ€§çš„ä¼˜ç‚¹ $\to$ ä¸´åºŠè®¡ç®— $\to$ å•†ä¸šæ€§è´¨ã€‚ çŒœæµ‹æ€§è¯è¯­potentiallyï¼Œ ç›®å‰çš„å›°çª˜æ€§è¯è¯­obstacleï¼‰ 

However, there are some limitations of this study. First, as an overall comparative study, the MAP-NN has not been optimized to either a specific vendor or a particular body region. The collection of more data will help improve the denoising performance and enhance the statistical significance of the denoising gains over the IR results. Second, LDCT and NDCT slices in a testing set may not be in perfect registration, which can affect the evaluation scores to some degree. Finally, our DL method was selected to be applicable to CT scans from all three vendors, from which we cannot have access to raw data. More powerful DL methods cannot be implemented without the data format. Despite these limitations, our overall conclusion has been encouraging that DL is either better than or comparable to IR. In collaboration with a vendor, our algorithm could be specifically trained with their data and achieve an even better performance than what we have described here using our agnostic algorithm. With the availability of raw data, CT denoising can be performed from the sinogram domain to the image space, utilizing all the information for the best denoising results. Clearly, it is now time for CT vendors to open their data format, perform machine learning and develop the next generation of CT image reconstruction algorithms in the DL framework.ï¼ˆè¿™æ®µç»™å‡ºäº†é™åˆ¶ï¼Œè¯´æ˜æ˜¯é€šç”¨æ€§çš„ä¸œè¥¿ï¼Œéœ€è¦ç‰¹å®šå‚å®¶å’Œç‰¹å®šéƒ¨ä½çš„ä¼˜åŒ–ä»¥åŠæ›´å¤šæ•°æ®ï¼Œç»™å‡ºæ–¹æ³•ã€‚keywordï¼š However ã€‚ Despite ï¼Œè½¬æŠ˜ï¼Œè¯´æ˜é™åˆ¶ä¹Ÿæ˜¯æ­»é™åˆ¶çš„é™åˆ¶ã€‚é€šç¯‡å¼ºè°ƒäº†å‚å®¶ä¸æ•°æ®ï¼Œè¯´æ˜é™åˆ¶æ˜¯å¯ä»¥ç ´é™¤çš„ã€‚ Clearlyï¼Œå‘¼åï¼‰registrationï¼šé…å‡†

In conclusion, our DL method provides better or similar image quality compared to commercial IR techniques from three CT vendors, and there is great potential for optimizing DL-based CT reconstruction methods that handle sinogram data directly.ï¼ˆdirectlyï¼‰

\-  â€œCompetitive performance of a modularized deep neural network compared to commercial algorithms for low-dose CT image reconstruction,â€ *Nat Mach Intell*, vol. 1, no. 6, pp. 269â€“276, Jun. 2019.

 artefacts: ä¼ªå½±ã€‚

### 10.3 The discussion of 2nd paper (Nat Biomed Eng, Nov. 2019)

To better understand the deep-learning model, we analyse the semantic representations learned from the model. Generally speaking, successful generation of volumetric images is possible only if the model is able to learn the semantic representation of the 3D structure from the input projections. Thus, for the same volume, the representations obtained via learning from different angular projections should be similar, since they describe the same underlying 3D scene. In Fig. [6a](https://www.nature.com/articles/s41551-019-0466-4#Fig6), we visualize the feature maps extracted from the transformation module for two testing samples. For visualization purposes, only 5 randomly chosen channels among the 4,096 feature maps are shown, each with a size of 4â€‰Ã—â€‰4 pixels. The feature maps learned from different numbers of 2D projections are displayed separately in different columns. The results show that, when different 2D views are given, the model extracts similar semantic representations of the underlying 3D scene. Furthermore, Fig. [6b](https://www.nature.com/articles/s41551-019-0466-4#Fig6) shows the visualization of *t*-distributed stochastic neighbour embedding (*t*-SNE) for the feature maps of 15 testing samples. The *t*-SNE technique is commonly used to visualize high-dimensional data by embedding each sample as a point in a 2D space[38](https://www.nature.com/articles/s41551-019-0466-4#ref-CR38). The four points in a cluster of the same colour represent the learned features from one-, two-, five- and ten-view reconstructions. The figure shows clustering behaviour for feature maps from the same sample, indicating that the model learns a similar representation from different 2D projections.

We also measure the similarity of the embedding representations by calculating the Euclidean distance between two feature maps. In this way, we compute a similarity score, ranging from 0 to 1, where high similarity (a score approaching 1) indicates that the distance between two feature maps is close to zero. We plot a correlation matrix (Fig. [6c](https://www.nature.com/articles/s41551-019-0466-4#Fig6)) among 50 randomly selected testing samples, with their feature representations extracted from one-view and two-view reconstruction models. The highest values stand out in the diagonal of the correlation matrix whereas other off-diagonal values remain relatively low. This illustrates that the two sets of feature representations learned from one-view and two-view projections for the same 3D scene are more similar or closer in Euclidean distance space compared with the feature representations learned from other different 3D scenes. This provides additional evidence supporting the capability of the model to learn a semantic representation of the 3D scene with a single projection.

Robustness against possible irregular breathing patterns is important for future clinical implementation of the approach. The robustness of deep networks against various perturbations is an intense area of research in artificial intelligence[39](https://www.nature.com/articles/s41551-019-0466-4#ref-CR39),[40](https://www.nature.com/articles/s41551-019-0466-4#ref-CR40),[41](https://www.nature.com/articles/s41551-019-0466-4#ref-CR41),[42](https://www.nature.com/articles/s41551-019-0466-4#ref-CR42),[43](https://www.nature.com/articles/s41551-019-0466-4#ref-CR43),[44](https://www.nature.com/articles/s41551-019-0466-4#ref-CR44),[45](https://www.nature.com/articles/s41551-019-0466-4#ref-CR45),[46](https://www.nature.com/articles/s41551-019-0466-4#ref-CR46). As summarized in ref. [43](https://www.nature.com/articles/s41551-019-0466-4#ref-CR43), possible solutions come in three categories: (1) the modification of network architectures (for example, adding more layers, changing the loss function and modifying the activation functions); (2) the use of external models as a network add-on to detect out-of-distribution data (for example, using an external detector to rectify the irregular data); and (3) the modification of the training-data distribution or the training strategy (for example, adding regularization, data augmentation or leveraging adversarial training). In (1), the efforts are focused on refining the learning models. In (2), irregular motions might be regarded as out-of-distribution data, where some potential techniques, such as a detector subnetwork[41](https://www.nature.com/articles/s41551-019-0466-4#ref-CR41) or the confidence-based method[42](https://www.nature.com/articles/s41551-019-0466-4#ref-CR42),[44](https://www.nature.com/articles/s41551-019-0466-4#ref-CR44), might be useful for detecting irregular input. Among the various methods, the modification of the training-data distribution is arguably the most straightforward way to proceed. The rationale is that if the irregularities can be incorporated effectively into the training dataset and the training strategy can be adjusted accordingly, the robustness of the trained model would be enhanced. To a certain extent, this has been elaborated in the example in Supplementary Fig. [7](https://www.nature.com/articles/s41551-019-0466-4#MOESM1), where it is demonstrated that, because of the inclusion of augmented training datasets with rotational transformations, the deep-learning approach is much more robust against a small rotation of the imaging subject than a conventional principal component analysis (PCA)-based method. Quantitative results of the study for the testing sample presented in Supplementary Fig. [7](https://www.nature.com/articles/s41551-019-0466-4#MOESM1) are shown in Supplementary Table [1](https://www.nature.com/articles/s41551-019-0466-4#MOESM1).

#### Outlook

We have described a deep-learning approach for volumetric imaging with ultra-sparse data sampling and a patient-specific prior. The data-driven strategy is capable of holistically extracting the feature characteristics embedded in a single projection or in a few 2D projections, and of transforming them into the corresponding 3D image through model learning. The image-feature space transformation plays an essential role in the ultra-sparse image reconstruction. At the training stage, the method incorporates diverse forms of a priori knowledge into the reconstruction. The manifold-mapping function is learned from the training datasets, rather than relying on any ad hoc form of motion trajectory. Although we have used X-ray imaging and patient-specific data, the concept and implementation of the approach could be extended to other imaging modalities or to other data domains with ultra-sparse sampling. Practically, single-view imaging represents a potential solution for many image-guided interventional procedures and may help to simplify the hardware of tomographic imaging systems.

\-  â€œPatient-specific reconstruction of volumetric computed tomography images from a single projection view via deep learning,â€ *Nat Biomed Eng*, vol. 3, no. 11, pp. 880â€“888, Nov. 2019.

è¯„ä»·ï¼šè¿™ç¯‡æ–‡ç« çš„discussionå†™å¾—è¾ƒä¸ºä¸“ä¸šæœ¯è¯­ã€‚

### 10.4 The discussion of 3rd paper (MAI)

Discussions and conclusions

In this paper, we propose a novel method based on the Wasserstein generative adversarial network to remove the Rician noise in MR images while effectively preserving the structural details. This network aims to process 3D volume data using a 3D convolutional neural network. In addition to the introduction of the WGAN framework, there are two more advantages to our method: the innovative generator structure and mixed weighted loss function. The generator is constructed with an autoencoder structure, which symmetrically contains convolutional and deconvolutional layers, aided by a residual structure. Another improvement of our method is the adaptation of the mixed loss function, which combines the MSE and perceptual losses with a weighted form.

The experimental results demonstrate that with the help of WGAN and perceptual loss, the CNN-based method is significantly improved in both qualitative and quantitative aspects. Compared to several state-of-the-art methods, including BM3D, PRI-NLM3D and CNN3D, our proposed RED-WGAN effectively avoids oversmoothing effects while preserving more details. Furthermore, to validate the robustness and generalization of our model, we trained our model with several specific noise levels and tested it on various noise levels. Meanwhile, real noisy clinical data were involved. In both cases, the proposed RED-WGAN model achieved a performance better than the traditional methods in both visual effects and quantitative results.

The computational cost of the deep learning-based method is worth mentioning. The training stage is the costliest step. Although the training procedure is usually performed on the GPU, it is still time-consuming. For our training set, when we alternatingly train the generator and discriminator networks, each epoch takes approximately 40 min. Although other methods, such as BM4D and PRI-NLM3D, do not need to train, their running times are much longer than the DL-based methods. In this paper, the average execution times for the clinical dataset for BM4D, PRI-NLM3D, CNN3D and RED-WGAN were 5.73, 4.16, 0.17 and 0.16â€¯s, respectively. In practice, the running time for DL-based methods can be further reduced by using GPU for testing.

In conclusion, the results obtained in the paper are encouraging and efficiently demonstrate the potential of deep learning-based methods for MRI denoising. In the future, instead of training on a specific noise level, we will try to extend our method to a more general form for different noise levels. Furthermore, incorporating the image reconstruction method may be interesting.

\- â€œDenoising of 3D magnetic resonance images using a residual encoderâ€“decoder Wasserstein generative adversarial network,â€ *Medical Image Analysis*, vol. 55, pp. 165â€“180, Jul. 2019.

### 10.5  The discussion of 4th paper (TMI)

With the development of CSC in recent years, CSC has been proven useful in many imaging problems, including super-resolution, image fusion, image decomposition and so on. Instead of dividing an image into overlapped patches, CSC directly works on the whole image, which maintains more details and avoids artifacts caused by patch aggregation. In this paper, we propose two methods based on CSC. The basic version introduces CSC into the PWLS reconstruction framework. To further improve the performance and preserve more structural information, gradient regularization on feature maps is imposed into the basic version. Qualitative and quantitative results demonstrate the merits of our methods.

In the experiments of Section IV-A and IV-B, the filters and parameters were the same, showing the generalization of the proposed methods and that there is no need to adjust the filters or the parameters patient by patient. We also examined the impacts of filters on our method. The experimental results show that PWLS-CSCGR can work well even with only four filters. PWLS-CSCGR is also robust to the training set or even without the training set and can be treated as an unsupervised learning method.

Importantly, another issue is the computational time. The main cost of our methods depends on two parts: training the filters and the reconstruction. Training 32 filters with 10 images costs 85 s of GPU. Because this operation is offline and there is no need for a large training set, this part will not be the main problem. On the other hand, the reconstruction is time-consuming. Although our methods have a similar heavy computational burden to PWLS-DL, several techniques, including parallel computing and advanced optimization methods, can be applied for acceleration.

One of the most important deep learning models is CNN, which is also based on the convolution operator. For CSC, a signal can be represented by a summation of convolutions between a set of filters and the corresponding feature maps, and the key point is to calculate the feature maps with certain (predetermined or adaptive) filters. CNN trains the cascaded filters to convolve with the inputs. Furthermore, current CNN-based methods still lack theoretical proof. Most deep learning methods are data-driven, and the results cannot be guaranteed without sufficient training data. However, CSC, as an unsupervised learning method, has a strict mathematical proof. This method is robust to the number of training samples (as shown in Sec. IV-C.3 and IV-C.4) and even without training data. On the other hand, the same groups analyzed the relationship between the CSC and CNN methods in [59], [60] and found that assuming that our signals originate from the multi-layer CSC model, the layered-thresholding pursuit algorithm for decomposing a given measurement vector $Y$ completely equals the forward propagation in CNNs. This interesting finding provides a new way to explore the interpretability of deep learning.

In conclusion, inspired by successful applications of CSC in the field of signal processing, we explored the potential of this method incorporating a PWLS image reconstruction framework, resulting in two novel algorithms referred to as PWLS-CSC and PWLS-CSCGR. We evaluated the proposed algorithms with simulated and real data. In the experimental results, our methods have been shown to be competitive with several state-of-art methods. The robustness of our methods was also investigated by extensive analysis with experimental configurations. In our future work, we will extend our methods to other CT imaging topics, such as metal artifact reduction and LDCT. Furthermore, the combination with deep learning-based methods is also an interesting direction.

\- â€œConvolutional Sparse Coding for Compressed Sensing CT Reconstruction,â€ *IEEE Transactions on Medical Imaging*, pp. 1â€“1, 2019.

è¯„ä»·ï¼šä»¥ä¸Šä¸¤ç¯‡è®ºæ–‡discussionå†™å¾—ååˆ†ä¸“ä¸šï¼Œç»å¸¸ä½¿ç”¨æœ¯è¯­å’Œæ–¹æ³•ç»†èŠ‚ã€‚

## Reference

[1] A. G. Huth, W. A. de Heer, T. L. Griffiths, F. E. Theunissen, and J. L. Gallant, â€œNatural speech reveals the semantic maps that tile human cerebral cortex,â€ *Nature*, vol. 532, no. 7600, pp. 453â€“458, Apr. 2016.

[2] H. Shan *et al.*, â€œCompetitive performance of a modularized deep neural network compared to commercial algorithms for low-dose CT image reconstruction,â€ *Nat Mach Intell*, vol. 1, no. 6, pp. 269â€“276, Jun. 2019.

# Week 11  Title and Abstract 

## 1. Task

ã€ç¬¬11å‘¨å­¦ä¹ ä»»åŠ¡ã€‘å¤§å®¶å¥½ï¼Œæœ¬å‘¨å­¦ä¹ å†…å®¹å¦‚ä¸‹ï¼š
1ã€Writing Journal. é˜…è¯»é€‰å®šæ–‡ç« çš„Titleå’ŒAbstractå¹¶è®°å½•æ”¶è·å’Œä½“ä¼šã€‚ï¼ˆæ³¨ï¼šå¯å‚è€ƒè¯¾ç¨‹èµ„æ–™"Week 11 - Task 1&2 "æ¥è®°å½•ï¼‰
2ã€ä¸»é¢˜é˜…è¯»ï¼šReview & Language Focusã€‚åä¸‰æœ¬ä¹¦å¯åœ¨library genesisä¸‹è½½ã€‚
ï¼ˆ1ï¼‰Chapter 4/5/6/10/11 (Adrian Wallwork. English for Writing Research Paper (2nd Edition), Springer. 2016ï¼‰
ï¼ˆ2ï¼‰Part 2 ï¼ˆThe textï¼ŒKaren Englander, Writing and publishing science research papers in English: A global perspectiveï¼‰
ï¼ˆ3ï¼‰æ•´æœ¬æµè§ˆï¼Œçº¦90é¡µï¼ˆFeak C & Swales, J., 2009, Telling a research story: writing a literature reviewï¼‰
ï¼ˆ4ï¼‰Chapter 11 ï¼ˆDiana Ridley 2012, The literature review: a step-by-step guide for studentsï¼‰

## 2. Gainings of Abstract

aï¼‰èƒŒæ™¯ï¼ˆ2-3å¥ï¼‰

ä»‹ç»èƒŒæ™¯ï¼Œç ”ç©¶ç›®æ ‡ã€‚

bï¼‰æ–¹æ³•ï¼ˆ2-3å¥ï¼‰

ç®€è¦å†™å‡ºï¼Œä¸»è¦æ˜¯æ•´ä½“è®¾è®¡ã€‚

cï¼‰ç»“æœï¼ˆ3-4å¥ï¼‰

å¦‚æœæ²¡æœ‰å¿…è¦ï¼Œä¸è¦ä½¿ç”¨ç‰¹å®šå€¼ã€‚è¿™é‡Œæ˜¯å¯¹resultsçš„æ€»ç»“å’Œæ¦‚æ‹¬ã€‚

dï¼‰ç»“è®ºï¼ˆ1-2å¥ï¼‰

é‡æ–°å¼•å…¥èƒŒæ™¯ï¼Œè§£é‡Šä¸ºä»€ä¹ˆè®ºæ–‡çš„ç»“æœå¾ˆé‡è¦ã€‚è®ºæ–‡é‡è¦æ€§ç»å¸¸ä¼šåœ¨Introï¼ŒAbstractï¼ŒDisccussionä¸­è®¨è®ºã€‚

## 3. Abstract å››é‡å¥ ğŸ¶

**å…·ä½“ä¾‹å­**ğŸŒ°ï¼š

è¿™é‡Œä»¥ä¸€ç¯‡ç¬”è€…æ–¹å‘çš„è®ºæ–‡ *A Deep Cascade of Convolutional Neural Networks for MR Image Reconstruction.* ä½œä¸ºä»‹ç»ï¼Œå¸Œæœ›è¿™ä¸ªæ€è·¯æ˜¯æ­£ç¡®çš„ã€‚

1ï¼‰ğŸµé¦–å…ˆèƒŒæ™¯ï¼šThe acquisition of Magnetic Resonance Imaging (MRI) is inherently slow.  

2ï¼‰ğŸµç„¶åæ–¹æ³•ï¼šInspired by recent advances in deep learning, we propose a framework for reconstructing MR images from undersampled data using a deep cascade of convolutional neural networks to accelerate the data acquisition process.  

3ï¼‰ğŸµéšåç»“æœï¼šWe show that for Cartesian undersampling of 2D cardiac MR images, the proposed method outperforms the state-of-the-art compressed sensing approaches, such as dictionary learning-based MRI (DLMRI) reconstruction, in terms of reconstruction error, perceptual quality and reconstruction speed for both 3-fold and 6-fold undersampling. Compared to DLMRI, the error produced by the method proposed is approximately twice as small, allowing to preserve anatomical structures more faithfully.  

4ï¼‰ğŸµæœ€åç»“è®ºï¼šUsing our method, each image can be reconstructed in 23 ms, which is fast enough to enable real time applications.  

## 4. Gainings of Title

è¿™ä¸ªé¢˜ç›®å°†è¢«æˆåƒä¸Šä¸‡çš„äººé˜…è¯»ã€‚ä¹Ÿè®¸å¾ˆå°‘æœ‰äººä¼šé˜…è¯»æ•´ç¯‡è®ºæ–‡ï¼Œä½†è®¸å¤šäººä¼šåœ¨åŸå§‹æœŸåˆŠï¼ŒäºŒçº§ï¼ˆæ‘˜è¦å’Œç´¢å¼•ï¼‰æ•°æ®åº“ï¼Œæœç´¢å¼•æ“è¾“å‡ºç­‰å…¶ä»–æ–¹é¢é˜…è¯»æ ‡é¢˜ã€‚å› æ­¤ï¼Œæ ‡é¢˜ä¸­çš„æ‰€æœ‰å•è¯éƒ½åº”è°¨æ…é€‰æ‹©ï¼Œå¹¶ä¸”å¿…é¡»è°¨æ…ç®¡ç†å½¼æ­¤ä¹‹é—´çš„å…³è”ã€‚

ç›®å‰ï¼Œå¥½Titleçš„å®šä¹‰ä¸ºï¼šå……åˆ†æè¿°è®ºæ–‡æ ¸å¿ƒå†…å®¹çš„æ‰€ç”¨å•è¯æœ€å°‘çš„ç»„åˆã€‚

åœ¨ä½œè€…çš„é¢†åŸŸï¼Œåº”è¯¥æ˜¯å¾ˆå¥½èµ·æ ‡é¢˜ï¼Œä¸€èˆ¬æ˜¯æå‡ºä¸€ç§æ–¹æ³•ï¼Œç„¶åç»™å®ƒå‘½åï¼Œä»‹ç»æ˜¯åœ¨æ ¸ç£å…±æŒ¯å›¾åƒé‡å»ºé¢†åŸŸå°±è¡Œï¼š

A Deep Cascade of Convolutional Neural
Networks for MR Image Reconstruction  

Image reconstruction by domain-transform
manifold learning  

Scanâ€specific robust artificialâ€neuralâ€networks for kâ€space
interpolation (RAKI) reconstruction: Databaseâ€free deep
learning for fast imaging  